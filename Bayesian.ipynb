{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatper 6. Bayesian Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ % Latex macros\n",
    "\\newcommand{\\mat}[1]{\\begin{pmatrix} #1 \\end{pmatrix}}\n",
    "\\newcommand{\\p}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\renewcommand{\\b}[1]{\\boldsymbol{#1}}\n",
    "\\newcommand{\\c}[1]{\\mathcal{#1}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents    \n",
    "* Bayes' theorem\n",
    "\n",
    "* Bayesian linear regression (Bishop, Chater 3)\n",
    "\n",
    "* Bayesian model comparison\n",
    "\n",
    "* Bayesian networks  (Bishop, Chater 8)\n",
    "\n",
    "* Dynamic Bayesian inference\n",
    "\n",
    "* Bayesian Brain\n",
    "    * Sensory psychophysics\n",
    "    * Cortical circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes’ Theorem\n",
    "\n",
    "Let us recall the two fundamental rules of probability regarding random variables $X$ and $Y$:\n",
    "\n",
    "* Sum rule:  \n",
    "\n",
    "$$  p(X) = \\sum_Y p(X, Y) $$\n",
    "\n",
    "* Product rule:  \n",
    "\n",
    "$$  p(X,Y) = p(Y|X) p(X) $$\n",
    "\n",
    "From the symmetry of joint probability $p(X,Y)=p(Y,X)$,  \n",
    "we have the relationship $p(X|Y)p(Y) = p(Y|X)p(X)$,  \n",
    "which brings us to Bayes' theorem:  \n",
    "\n",
    "$$  p(X|Y) = \\frac{p(Y|X)p(X)}{p(Y)}. $$\n",
    "\n",
    "Using Bayes' theorem, we can convert one conditional probability to the other.\n",
    "This simple formula has turned out to be very insightful in the context of sensory processing and learning. \n",
    "\n",
    "Suppose $X$ is the variable of your interest, such as the existence of your target, and $Y$ is a noisey sensory input. What sensory input $Y$ you would receive if your target exists or not is represented by a sensory model $p(Y|X)$.  \n",
    "\n",
    "* Your knowledge or assumption about existence of your target is represented by $p(X)$, called *prior probability*.  \n",
    "\n",
    "* For a given sensory input $y$, $p(Y=y|X)$ as a function of $X$ is called the *likelihood* of the state $X$.\n",
    "\n",
    "* The probability of the target $X$ existing after observing $y$, $p(X|Y=y)$ is called the *posterior probability*.\n",
    "\n",
    "Bayes' theorem gives a theoretical basis for the intuition that the posterior probability is proportional to the product of the prior prbability and the likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: mouse in a bush\n",
    "\n",
    "You are a cat chasing a mouse and heard a rustuling sound from a bush. \n",
    "About half of the case a hiding mouse makes a sound, but about 10% of the time you hear rustling just by the wind. \n",
    "How would you estimate the probability for a mouse hiding in the bush?\n",
    "\n",
    "| $p(Y \\vert X)$ | no mouse $X=0$ | mouse hiding $X=1$ |\n",
    "| --- | :---: | :---: |\n",
    "| no sound $Y=0$  | 0.9 | 0.5 |\n",
    "| sound $Y=1$  | 0.1 | 0.5 |\n",
    "\n",
    "For example, if you heard a sound, $Y=1$, what is the probability of a mouse hiding behind the bush, $p(X=1|Y=1)$?\n",
    "From the above table, 0.5?\n",
    "\n",
    "No, actually. In the 'heard' row, 0.1 and 0.5 do not sum up to one. They are likelihoods $p(Y=1|X)$, but not probability distribution $p(X|Y=1)$ for the mouse to be in the bush or not.\n",
    "\n",
    "The mouse ran into other nearby bushes, so you assume that the prior probability of the mouse in this bush is 30%:\n",
    "\n",
    "| prior probability | no mouse $X=0$ | mouse hiding $X=1$ |\n",
    "| :---: | :---: | :---: |\n",
    "| $p(X)$ | 0.7 | 0.3 |\n",
    "\n",
    "By having this prior probability, we can use Bayes' theorem:\n",
    "\n",
    "$$  p(X=1|Y=1) = \\frac{p(Y=1|X=1)p(X=1)}{p(Y=1|X=0)p(X=0)+p(Y=1|X=1)p(X=1)}  $$\n",
    "\n",
    "$$  = \\frac{0.5*0.3}{0.1*0.7+0.5*0.3}\n",
    "    = \\frac{0.15}{0.07+0.15} \n",
    "    = \\frac{0.15}{0.22} \\simeq 0.68  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Bayesian Inference\n",
    "\n",
    "A useful property of Bayesian inference is that you can apply it iteratively to incoming data stream.\n",
    "\n",
    "We denote the sequence of observations up to time $t$ as\n",
    "\n",
    "$$  y_{1:t}=(y_1,...,y_t)  $$\n",
    "\n",
    "and want to estimate the cause $x$ of these observations\n",
    "\n",
    "$$  p(x|y_{1:t}) = \\frac{p(y_{1:t}|x)\\ p(x)}{p(y_{1:t})}  $$\n",
    "\n",
    "If the observations are independent, their joint distribution is a product\n",
    "\n",
    "$$  p(y_{1:t}|x) = p(y_1|x)\\cdots p(y_t|x)  $$\n",
    "and thus the posterior can be decomposed as\n",
    "\n",
    "$$  p(x|y_{1:t}) = \\frac{p(y_1|x)\\cdots p(y_{t-1}|x)\\ p(y_t|x)\\ p(x)}{p(y_1)\\cdots p(y_{t-1})\\ p(y_t)}  $$\n",
    "\n",
    "$$  = \\frac{p(y_1|x)\\cdots p(y_{t-1}|x)\\ p(x)}{p(y_1)\\cdots p(y_{t-1}) }\\ \\frac{p(y_t|x)}{p(y_t)}  $$\n",
    "\n",
    "$$  = \\frac{p(x|y_{1:t-1})\\ p(y_t|x)}{p(y_t)}.  $$\n",
    "\n",
    "This means that the posterior $p(x|y_{1:t-1})$ that you computed by time $t-1$ serves as the prior to be combined with the likelihood for the new coming data $p(y_t|x)$ for computing the new posterior $p(x|y_{1:t})$.\n",
    "\n",
    "This iterative update of the posterior is practically helpful in online inference utilizing whatever data available so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coin toss\n",
    "\n",
    "Here is a simple example of estimating the parameter $\\mu$, probability for a coin to land head up, during multiple tosses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take samples\n",
    "mu = 0.3  # probability of head\n",
    "N = 8   # number of samples\n",
    "y = np.random.choice(2, N, p=[1-mu, mu]) # binary observation sequence\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = 0.01  # plot step\n",
    "x = np.arange( 0, 1, dx)  # range of the parameter\n",
    "prior = np.ones( len(x))  # Assume a uniform prior\n",
    "plt.figure(figsize=(6,10))\n",
    "for t in range(N):\n",
    "    plt.subplot(4, 2, t+1)  # a new figure\n",
    "    # prior\n",
    "    plt.plot( x, prior, 'b')\n",
    "    # observation\n",
    "    plt.plot( y[0:t+1], np.arange(t+1)/N, 'ko')\n",
    "    # likelihood\n",
    "    likelihood = x*y[t] + (1-x)*(1-y[t]) # theta if head, 1-theta if tail\n",
    "    plt.plot( x, likelihood, 'g')\n",
    "    # product\n",
    "    prilik = prior*likelihood\n",
    "    plt.plot( x, prilik,'c')\n",
    "    # posterior by normalization\n",
    "    marginal = sum(prilik)*dx    # integrate over the parameter range\n",
    "    posterior = prilik/marginal  # normalize\n",
    "    plt.plot( x, posterior, 'r')\n",
    "    plt.xlabel(r'$\\mu$')\n",
    "    if t==0:\n",
    "        plt.legend(('prior', 'observation', 'likelihood', 'prior*like.', 'posterior'))\n",
    "    plt.title(f't = {t+1}')\n",
    "    # posterior as a new prior\n",
    "    prior = posterior\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "As more data are collected, the posterior distribution of $\\mu$ becomes sharper and colser to the true value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisy observation\n",
    "\n",
    "Estimate the mean $\\mu$ and the standard deviationn $\\sigma$ from noisy observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noisy observation: y = N(mu,sigma)\n",
    "mu = 1\n",
    "sigma = 2\n",
    "N = 12\n",
    "y = mu + sigma*np.random.randn(N)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start from a uniform prior\n",
    "rmu = 5; dmu = 0.2   # range and step of mu\n",
    "rsig = 5;  dsig = 0.2 # range and step of sigma\n",
    "m = np.arange(-rmu, rmu, dmu)\n",
    "s = np.arange(rsig, 0, -dsig)\n",
    "M, S = np.meshgrid(m, s)\n",
    "prior = np.ones_like(M)/(2*rmu*rsig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(N):\n",
    "    plt.figure()\n",
    "    plt.subplot(1, 2, 1)\n",
    "    # observation\n",
    "    plt.plot( y[0:n+1], dsig+rsig*np.arange(n+1)/N, 'w+')\n",
    "    # likelihood\n",
    "    likelihood = np.exp(-((y[n]-M)/S)**2/2)/(np.sqrt(2*np.pi)*S)\n",
    "    plt.imshow(likelihood, extent=(-rmu,rmu,0,rsig))\n",
    "    plt.xlabel(r'$\\mu$'); plt.ylabel(r'$\\sigma$');\n",
    "    plt.title(f'likelihood {n+1}')\n",
    "    # posterior\n",
    "    plt.subplot(1, 2, 2)\n",
    "    prilik = prior*likelihood\n",
    "    #plt.imshow(prilik, extent=(-rmu,rmu,0,rsig))\n",
    "    marginal = np.sum(prilik)*dmu*dsig\n",
    "    posterior = prilik/marginal\n",
    "    plt.imshow(posterior, extent=(-rmu,rmu,0,rsig))\n",
    "    plt.xlabel(r'$\\mu$'); plt.ylabel(r'$\\sigma$');\n",
    "    plt.title(f'posterior {n+1}')\n",
    "    prior = posterior  # new prior\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian approaches in machine learning\n",
    "\n",
    "\"Bayesian\" is quite popular in machine learning, but it is used for different meanings:\n",
    "\n",
    "* To combine prior knowledge and the likelihood from observation\n",
    "\n",
    "* To assume a graphical model of data generation for estimation of the causes\n",
    "\n",
    "* To estimate the distribution of a variable, not a single point\n",
    "\n",
    "In supervised learning:\n",
    "* avoid over fitting by introducing a prior distribution on the parameters\n",
    "* compare models by their probability of producing observed data\n",
    "\n",
    "In reinforcement learning:\n",
    "* infer the environmental state from incomplete observation\n",
    "* estimate the distribution of reward, not just the expectation\n",
    "\n",
    "In unsupervised learning:\n",
    "* infer hidden variables behind data\n",
    "    * e.g. responsibility in Mixtures of Gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Linear Regression\n",
    "\n",
    "The standard linear regression (Chapter 3) assumes a linear regression function with additive noise \n",
    "$$ t_n = \\b{w}^T\\b{x}_n + \\epsilon $$\n",
    "where $p(\\epsilon)=\\mathcal{N}(0,\\beta^{-1})$.\n",
    "\n",
    "In Bayesian linear regression, we assume that the weights are sampled from a prior distribution $p(\\b{w})=\\mathcal{N}(\\b{0},\\alpha^{-1}I)$.\n",
    "\n",
    "The likelihood of the parameter $\\b{w}$ for the target output $\\b{t}$ is\n",
    "\n",
    "$$ p(\\b{t}|X, \\b{w}, \\beta) = \\prod_{n=1}^N \\mathcal{N}(t_n|\\b{w}^T\\b{x},\\beta^{-1}) $$\n",
    "\n",
    "When both the prior and likelihood are Gaussian, the posterior will also be Gaussian and have the form:\n",
    "\n",
    "$$ p(\\b{w}|\\b{t}) = \\mathcal{N}(\\b{w}|\\b{m},S) $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \\b{m} = \\beta S X^T \\bf{t} $$\n",
    "\n",
    "and\n",
    "\n",
    "$$ S = (\\alpha I + \\beta X^T X)^{-1} $$\n",
    "\n",
    "If we let $\\alpha=0$, i.e. infinitely large variance for the weight prior, this is equivalent to regular linear regression. Introducing a penalty term is commonly done in linear regression as\n",
    "\n",
    "$$ E(\\b{w}) = \\frac{\\beta}{2}\\sum_{n=1}^N \\{t_n - \\b{w}^T \\b{x}_n\\}^2\n",
    "+ \\frac{\\alpha}{2} \\b{w}^T\\b{w} $$\n",
    "\n",
    "$$ = \\frac{\\beta}{2} ||\\b{t} - X \\b{w}||^2 + \\frac{\\alpha}{2} ||\\b{w}||^2. $$\n",
    "\n",
    "The Bayesian regression gives a probabilistic interpretation on the role of the regularization parameter $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use this frequently\n",
    "def gauss(x, mu=0, sigma=1):\n",
    "    \"\"\"Gaussian distribution\"\"\"\n",
    "    return np.exp(-((x-mu)/sigma)**2/2)/(np.sqrt(2*np.pi)*sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributions in the parameter and data spaces\n",
    "alpha = 1.  # inverse variance of weight prior\n",
    "beta = 10  # inverse variance of observation noise\n",
    "# prior distribution of weights\n",
    "W = np.linspace(-3, 3, 30)\n",
    "W0, W1 = np.meshgrid(W, W)\n",
    "pw = gauss(W0)*gauss(W1)\n",
    "# plot the distribution\n",
    "plt.subplot(1,2,1)\n",
    "plt.pcolormesh(W, W, pw)  \n",
    "# sample weight from prior distribution\n",
    "K = 10  \n",
    "wpri = np.random.normal(scale=alpha**-0.5,size=2*K).reshape(K,2)\n",
    "plt.plot(wpri[:,0], wpri[:,1], \"r+\")\n",
    "plt.axis('square');\n",
    "plt.title(\"Prior\"); plt.xlabel(\"w0\"); plt.ylabel(\"w1\");\n",
    "# plot model samples\n",
    "xrange = np.array([-1., 1.])   # range of input x\n",
    "plt.subplot(1,2,2)\n",
    "for k in range(K):\n",
    "    #wpri[1,k]*X\n",
    "    plt.plot(xrange, wpri[k,0]+wpri[k,1]*xrange)\n",
    "plt.title(\"Model samples\"); plt.xlabel(\"x\"); plt.ylabel(\"y\");    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after observation of data\n",
    "N = 1\n",
    "wt = np.array([-1, 1])  # 'true' weights\n",
    "# sample data\n",
    "X = np.random.uniform(xrange[0], xrange[1], size=N)\n",
    "X = np.c_[np.ones(N), X]  # prepend 1 in the leftmost column\n",
    "t = wt@X.T + np.random.normal(size=N)/np.sqrt(beta)\n",
    "plt.subplot(2,2,2)  # start from top right\n",
    "plt.plot(xrange, wt[0]+wt[1]*xrange, \"g\")\n",
    "plt.plot(X[:,1], t, \"r.\")  # training data\n",
    "plt.xlim(xrange)\n",
    "plt.title(\"Data\"); plt.xlabel(\"x\"); plt.ylabel(\"y\");\n",
    "# likelihood\n",
    "like = 1\n",
    "for n in range(N):\n",
    "    like = like*gauss(t[n] - (W0+W1*X[n,1]), sigma=beta**(-0.5))\n",
    "plt.subplot(2,2,1)   # top left\n",
    "plt.pcolormesh(W, W, like)\n",
    "plt.axis('square')\n",
    "plt.title(\"Likelihood\"); plt.xlabel(\"w0\"); plt.ylabel(\"w1\");\n",
    "# new posterior\n",
    "plt.subplot(2,2,3)\n",
    "post = pw*like\n",
    "plt.pcolormesh(W, W, post)\n",
    "plt.axis('square')\n",
    "plt.title(\"Posterior\"); plt.xlabel(\"w0\"); plt.ylabel(\"w1\");\n",
    "S = np.linalg.inv(alpha*np.eye(2) + beta*X.T@X)\n",
    "m = beta*S@X.T@t\n",
    "print('m =', m)\n",
    "print('S =', S)\n",
    "# sample weights\n",
    "wpost = np.random.multivariate_normal(m, S, K)\n",
    "plt.plot(wpost[:,0], wpost[:,1], \"r+\")\n",
    "# plot model samples\n",
    "xrange = np.array([-1., 1.])   # range of input x\n",
    "plt.subplot(2,2,4)\n",
    "for k in range(K):\n",
    "    #wpri[1,k]*X\n",
    "    plt.plot(xrange, wpost[k,0]+wpost[k,1]*xrange)\n",
    "plt.plot(X[:,1], t, \"r.\")  # training data\n",
    "plt.title(\"Model samples\"); plt.xlabel(\"x\"); plt.ylabel(\"y\");\n",
    "plt.tight_layout()  # adjust subplot margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive distribution\n",
    "In Bayesian regression, the result is not one weight vector, but a distribution in the weight space. Then it is reasonable to consider the distribution of the output considering such uncertainty in the weigts.\n",
    "\n",
    "The output $y$ for a new input $\\b{x}$ should have the distribution\n",
    "\n",
    "$$ p(y|\\b{x},\\b{t},\\alpha,\\beta) \n",
    " = \\int p(y|\\b{x},\\b{w},\\beta)  p(\\b{w}|\\b{t},\\alpha,\\beta) d\\b{w} $$\n",
    "\n",
    "$$ = \\mathcal{N}(t|\\b{m}^T \\b{x}, \\sigma^2(\\b{x})) $$\n",
    "where the variance of the output is given by\n",
    "\n",
    "$$ \\sigma^2(\\b{x}) = \\beta^{-1} + \\b{x}^T S \\b{x} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see the example of approximating a sine function by Gaussian basis functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D Gaussian basis functions \n",
    "def gbf1(x, xrange=[-1.,1.], M=10):\n",
    "    \"\"\"Gaussian basis functions: x can be a 1D array\"\"\"\n",
    "    xc = np.linspace(xrange[0], xrange[1], num=M)  # centers\n",
    "    xd = (xc[1]-xc[0])  # interval\n",
    "    # x can be an array for N data points\n",
    "    return np.exp(-((np.tile(x,[M,1]).T - xc)/xd)**2)\n",
    "# example\n",
    "x = np.linspace(-1, 1, 100)\n",
    "plt.plot(x, gbf1(x, M=5));\n",
    "plt.xlabel(\"x\"); plt.ylabel(\"phi\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blr(X, t, alpha=1., beta=10.):\n",
    "    \"\"\"Bayesian linear regression\n",
    "    alpha: inv. variance of weight prior \n",
    "    beta: inv. variance of observation noise\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    S = np.linalg.inv(alpha*np.eye(D) + beta*X.T@X) # posterior covariance\n",
    "    m = beta*S@X.T@t   # posterior mean\n",
    "    return m, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target(x):\n",
    "    \"\"\"Target function\"\"\"\n",
    "    return np.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "N = 20\n",
    "eps = 0.2  # noise size\n",
    "xr = 4   # range of x\n",
    "x = np.random.uniform(-xr, xr, size=N)  \n",
    "f = target(x)  # target function\n",
    "t = f + np.random.normal(scale=eps, size=N) # with noise\n",
    "# data for testing/plotting\n",
    "Np = 100\n",
    "xp = np.linspace(-xr, xr, Np)\n",
    "fp = target(xp)\n",
    "plt.plot(xp, fp, \"g\")  # target function\n",
    "plt.plot(x, t, \"ro\");  # training data\n",
    "plt.xlabel(\"x\"); plt.ylabel(\"y\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 10  # number of basis functions\n",
    "Phi = gbf1(x, [-xr,xr], M)  # Gaussian basis functions\n",
    "m, S = blr(Phi, t, alpha=1, beta=25)  # Bayesian linear regression\n",
    "print(m)\n",
    "# test data\n",
    "Phip = gbf1(xp, [-xr,xr], M)\n",
    "yp = Phip@m.T\n",
    "plt.plot(xp, fp, \"g\")  # target function\n",
    "plt.plot(x, t, \"ro\");  # training data\n",
    "plt.plot(xp, yp, \"b\");  # MAP estimate\n",
    "# predictive distribution\n",
    "sigma = np.sqrt(1/beta + np.sum(Phip@S*Phip, axis=1))\n",
    "plt.plot(xp, yp+sigma, \"c\")\n",
    "plt.plot(xp, yp-sigma, \"c\")\n",
    "plt.xlabel(\"x\"); plt.ylabel(\"y\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how $N$, $M$, $\\alpha$ and $\\beta$ affect the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian model comparison\n",
    "\n",
    "We have so far considered Bayesian inference of the parameter $\\b{w}$ for a given model $\\c{M}$, such as a regression model with some input variables, but we can also think of Bayesian inference of probability over models $\\c{M}_i$, such as regression models with different choices of input variables, given data $\\c{D}$\n",
    "\n",
    "$$ p(\\c{M}_i|\\c{D}) \\propto p(\\c{M}_i) p(\\c{D}|\\c{M}_i). $$\n",
    "\n",
    "Here $p(\\c{D}|\\c{M}_i)$, the likelihood of a model given data, is called the *evidence* of the model. \n",
    "\n",
    "If we include a model explicitly in our Bayesian parameter estimation, we have\n",
    "\n",
    "$$ p(\\b{w}|\\c{D},\\c{M}_i) = \\frac{p(\\c{D}|\\b{w},\\c{M}_i)p(\\b{w}|\\c{M}_i)}{p(\\c{D}|\\c{M}_i)}, $$\n",
    "\n",
    "where we have the *evidence* as the normalizing denominator\n",
    "\n",
    "$$ p(\\c{D}|\\c{M}_i) = \\int p(\\c{D}|\\b{w},\\c{M}_i)p(\\b{w}|\\c{M}_i) d\\b{w}. $$\n",
    "\n",
    "This is also called *marginal likelihood* because it is the likelihood of the model with its parameters marginalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing model evidence\n",
    "\n",
    "In Bayesian linear regression, the model evidence with the *hyperparamters* $\\alpha$ (weight prior) and $\\beta$ (observation noise) is given by integration over all the range of the weight parameters $\\b{w}$:\n",
    "\n",
    "$$ p(\\b{t}|\\alpha,\\beta) = \\int p(\\b{t}|\\b{w},\\beta)p(\\b{w}|\\alpha) d\\b{w}, $$\n",
    "\n",
    "By further integrating this over the prior distribution of $\\alpha$ and $\\beta$ we have the evidence for the full model.\n",
    "\n",
    "A practical approximation is to find $\\alpha$ and $\\beta$ that maximize $p(\\b{t}|\\alpha,\\beta)$.\n",
    "\n",
    "The log evidence is given as (Bishop, Chapter 3.5)\n",
    "\n",
    "$$ \\log p(\\b{t}|\\alpha,\\beta) \n",
    "    = -\\frac{\\beta}{2} ||\\b{t}-X\\b{m}||^2 - \\frac{\\alpha}{2} ||\\b{m}||^2 $$\n",
    "\n",
    "$$  + \\frac{1}{2}\\log|S| + \\frac{D}{2}\\log\\alpha + \\frac{N}{2}(\\log\\beta - \\log(2\\pi)) $$\n",
    "\n",
    "where $\\b{m}$ and $S$ also depend on $\\alpha$ and $\\beta$.\n",
    "\n",
    "For $N>>D$, the evidence is maximized by\n",
    "\n",
    "$$ \\alpha^{-1} = \\frac{1}{D}||\\b{m}||^2 $$\n",
    "\n",
    "$$ \\beta^{-1} = \\frac{1}{N}||\\b{t} - X \\b{w}||^2. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logev(X, t, m, S):\n",
    "    \"\"\"log evidence for Bayesian regression\n",
    "    m: posterior mean\n",
    "    S: posterior covariance\n",
    "    alpha: inv. variance of weight prior \n",
    "    beta: inv. variance of observation noise\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    #S = np.linalg.inv(alpha*np.eye(D) + beta*X.T@X) # posterior covariance\n",
    "    #m = beta*S@X.T@t   # posterior mean\n",
    "    em = t - X@m.T  # error with MAP estimate\n",
    "    alpha = D/np.dot(m,m)\n",
    "    beta = N/np.dot(em,em)\n",
    "    # log evidence\n",
    "    lev = -beta/2*np.dot(em,em) - alpha/2*np.dot(m,m) + np.log(abs(np.linalg.det(S)))/2 + D/2*np.log(alpha) + N/2*(np.log(beta/(2*np.pi)))\n",
    "    return lev, alpha, beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try computing log evidence for different $M$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try different values of M\n",
    "Max = 10  # max number of basis functions\n",
    "mse = np.zeros(Max)  # mean square errors\n",
    "lev = np.zeros(Max)  # log evidences\n",
    "for M in range(2,Max):\n",
    "    Phi = gbf1(x, [-xr,xr], M)  # Gaussian basis functions\n",
    "    m, S = blr(Phi, t, alpha=1, beta=25)\n",
    "    lev[M], alpha, beta = logev(Phi, t, m, S)\n",
    "    # test data\n",
    "    Phip = gbf1(xp, [-xr,xr], M)  # Gaussian basis functions\n",
    "    err = fp - Phip@m.T  # validation error\n",
    "    mse[M] = np.dot(err,err)/Np\n",
    "    print(M, alpha, beta, lev[M], mse[M])\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(np.arange(2,Max), mse[2:], \"r\"); plt.ylabel(\"mse\");\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(np.arange(2,Max), lev[2:], \"b\"); plt.ylabel(\"log evidence\");\n",
    "plt.xlabel(\"M\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen in the example of Bayesian linear regression, statistical machine learning assumes a *generative model* of the observed data and infer the posterior probability of variables of your interest, after marginalizing other unobserved variables.\n",
    "\n",
    "In doing so, representation of the relationships by graphs with random variables as nodes (or vertices) and joint or conditional probabilities as links (or edges or arcs) have turned out to be very useful. They are called *graphical models*.\n",
    "\n",
    "Directed graphs representing conditional probabilities by arrows (directed edges) are called *Bayesian networks*.\n",
    "\n",
    "For example, Bayesian linear regression can be represented as a Bayesian network as below.\n",
    "\n",
    "><img src=\"figures/BN_blr.png\" width=\"200px\">\n",
    ">Graphical model for the Bayesian linear regression.\n",
    "\n",
    "Inference in Bayesian network goes like this: as values of some variables are observed, \n",
    "* *clamp* the values of the nodes where observation was made.\n",
    "* compute the posterior distributions of the nodes along the graph by repeating Bayesian inference and marginalization\n",
    "\n",
    "In doing this, the *conditional independence* of the nodes allows efficient computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on a chain\n",
    "\n",
    "Here we consider the simplest case of a chain of discrete random variables. \n",
    "\n",
    ">![Chain](figures/BN_chain.png)\n",
    ">Graphical model of a chain of states.\n",
    "\n",
    "For each node, the variable takes an integer value $x_n \\in \\{1,...,K_n\\}$ and we consider the joint distribution over the entire nodes:\n",
    "\n",
    "$$  p(x_1,...,x_N) = p(x_1)p(x_2|x_1) \\cdots p(x_{N-1}|x_{N-2})p(x_N|x_{N-1}). $$\n",
    "\n",
    "When an observation $x_N=k$ is made at the end node, we would consider the posterior distribution\n",
    "\n",
    "$$  p(x_1,...,x_{N-1}|x_N=k) \\propto \n",
    "    p(x_1)p(x_2|x_1) \\cdots p(x_{N-1}|x_{N-2})p(x_N=k|x_{N-1}).  $$\n",
    "\n",
    "The posterior distribution of each node $x_n$ is given by marginalization\n",
    "\n",
    "$$  p(x_n|x_N=k) \\propto \\sum_{x_1}\\cdots\\sum_{x_{n-1}}\\ \n",
    "    \\sum_{x_{n+1}}\\cdots\\sum_{x_N}p(x_1,...,x_{N-1}|x_N=k) $$\n",
    "    \n",
    "$$  = \\left\\{\\sum_{x_{n-1}}p(x_n|x_{n-1}) \\cdots\n",
    "    \\sum_{x_1}p(x_2|x_1)p(x_1)\\right\\} $$\n",
    "    \n",
    "$$  \\times \\left\\{\\sum_{x_{n+1}}p(x_{n+1}|x_n) \\cdots \n",
    "    \\sum_{x_{N-1}}p(x_{N-1}|x_{N-2}) \\sum_{x_N}p(x_N=k|x_{N-1})\\right\\}  $$\n",
    "\n",
    "This can be computed efficiently by passing two *messages*:\n",
    "\n",
    "* Forward message $\\alpha_n$ of prior:\n",
    "\n",
    "$$ \\alpha_1 = p(x_1)$$\n",
    "\n",
    "$$ \\alpha_n = \\sum_{x_{n-1}} p(x_n|x_{n-1}) \\alpha_{n-1} $$\n",
    "\n",
    "* Backward message $\\beta_n$ of likelihood:\n",
    "\n",
    "$$ \\beta_N = (0,...,1,...0) $$\n",
    "with $1$ at $k$-th component and\n",
    "\n",
    "$$ \\beta_n = \\sum_{x_{n+1}} p(x_{n+1}|x_n) \\beta_{n+1} $$\n",
    "\n",
    "The posterior distribution for each node is then given by their product\n",
    "\n",
    "$$  p(x_n|x_N=k) \\propto \\alpha_n \\beta_n. $$\n",
    "\n",
    "This is called *forward-backward* algorithm. \n",
    "\n",
    "This can be generalized to tree-like networks and the algorithm using forward and backward message passing is known as *belief propagation*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov chain\n",
    "\n",
    "Here is an example of inference in a Markov chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Markov:\n",
    "    \"\"\"Class for a Markov chain\"\"\"\n",
    "    \n",
    "    def __init__(self, ptr):\n",
    "        \"\"\"Create a new environment\"\"\"\n",
    "        self.ptr = ptr  # transition matrix p(x'|x)\n",
    "        self.Ns = len(ptr)  # number of states\n",
    "        \n",
    "    def sample(self, x0=0, step=1):\n",
    "        \"\"\"generate a sample sequence from x0\"\"\"\n",
    "        seq = np.zeros(step+1, dtype=int) # sequence buffer\n",
    "        seq[0] = x0\n",
    "        for t in range(step):\n",
    "            pt1 = self.ptr[:, seq[t]] # prob. of new states\n",
    "            seq[t+1] = np.random.choice(self.Ns, p=pt1) # sample \n",
    "        return seq\n",
    "    \n",
    "    def forward(self, p0, step=1):\n",
    "        \"\"\"forward message from initial distribution p0\"\"\"\n",
    "        alpha = np.zeros((step+1, self.Ns)) # priors\n",
    "        alpha[0] = p0  # initial distribution\n",
    "        for t in range(step):\n",
    "            alpha[t+1] = self.ptr @ alpha[t] \n",
    "        return alpha\n",
    "\n",
    "    def backward(self, obs, step=1):\n",
    "        \"\"\"backward message from terminal observaion\"\"\"\n",
    "        beta = np.zeros((step+1, self.Ns)) # likelihoods\n",
    "        beta[-1] = obs  # observation\n",
    "        for t in range(step, 0, -1): # toward 0\n",
    "            beta[t-1] = beta[t] @ self.ptr\n",
    "        return beta\n",
    "    \n",
    "    def posterior(self, p0, obs, step):\n",
    "        \"\"\"forward-backward algorithm\"\"\"\n",
    "        alpha = self.forward(p0, step)\n",
    "        beta = self.backward(obs, step)\n",
    "        post = alpha*beta\n",
    "        for t in range(step+1):\n",
    "            post[t] = post[t]/sum(post[t])  # normalize        \n",
    "        return post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of directed random walk on a ring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stochastic cycling on a ring\n",
    "ns = 6   # ring size\n",
    "ps = 0.3  # shift probability\n",
    "Ptr = np.zeros((ns, ns))  # transition matrix\n",
    "for i in range(ns):\n",
    "    Ptr[i,i] = 1 - ps\n",
    "    Ptr[(i+1)%ns, i] = ps\n",
    "plt.imshow(Ptr)\n",
    "# create a Markov chain\n",
    "ring = Markov(Ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a sample trajectory\n",
    "T = 15\n",
    "ring.sample(1, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward message passing\n",
    "alpha = ring.forward([0,0,1,0,0,0], T)\n",
    "plt.imshow(alpha.T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward message passing\n",
    "beta = ring.backward([0,0,0,1,0,0], T)\n",
    "plt.imshow(beta.T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior by their products\n",
    "post = ring.posterior([0,0,1,0,0,0], [0,0,0,1,0,0], T)\n",
    "plt.imshow(post.T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a little shifted observation\n",
    "post = ring.posterior([0,0,1,0,0,0], [0,0,0,0,1,0], T)\n",
    "plt.imshow(post.T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# longer sequence\n",
    "post = ring.posterior([0,0,1,0,0,0], [0,0,0,0,1,0], 3*T)\n",
    "plt.imshow(post.T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Bayesian Inference\n",
    "\n",
    "Iterative Bayesian inference can be generalized to the case when the hidden variable $x$ changes dynamically.\n",
    "\n",
    "We denote the sequence of observation as\n",
    "\n",
    "$$  y_{1:t}=(y_1,..,y_t) $$\n",
    "\n",
    "and the history of underlying state variable as\n",
    "\n",
    "$$  x_{1:t}=(x_1,..,x_t). $$\n",
    "\n",
    "We assume two conditional probability distributions:\n",
    "\n",
    "* Dynamics model: $p(x’|x)$\n",
    "\n",
    "* Observation model: $p(y|x)$\n",
    "\n",
    "Using the posterior $p(x_t|y_{1:t})$ computed from the data up to time $t$, we use the dymamics model to compute the *predictive prior*:\n",
    "\n",
    "$$  p(x_{t+1}|y_{1:t}) = \\int p(x_{t+1}|x_t) p(x_t|y_{1:t}) dx_t $$\n",
    "\n",
    "by integrating or summing over the possible range of $x$.\n",
    "\n",
    "We can combine this prior with the new coming data $y_{t+1}$ to update the posterior as:\n",
    "\n",
    "$$  p(x_{t+1}|y_{1:t+1}) \n",
    " = \\frac{p(y_{t+1}|x_{t+1}) p(x_{t+1}|y_{1:t})}{ p(y_{1:t+1})}. $$\n",
    "\n",
    "This is called *dynamic Bayesian inference* and allows real-time tracking of hidden variables from noisy observations.\n",
    "\n",
    "When $x$ is discrete, the process is called *hidden Markov model (HMM)*, which has been used extensively speech processing.\n",
    "\n",
    "Another example is *Kalman filter*, in which $x$ and $y$ are continuous and the dynamics and observation models are linear mapping with Gaussian noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Hidden Markov model\n",
    "\n",
    "Here is a simple implementation of HMM based on the Markov chain above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM(Markov):\n",
    "    \"\"\"Hidden Markov model\"\"\"\n",
    "\n",
    "    def __init__(self, ptr, pobs):\n",
    "        \"\"\"Create HMM with transition and observation models\"\"\"\n",
    "        super().__init__(ptr)\n",
    "        self.pobs = pobs  # observation model\n",
    "        self.No = len(pobs)  # number of observations\n",
    "        self.pst = np.ones(self.Ns)/self.Ns  # state distribution\n",
    "        self.pred = np.zeros(self.Ns)  # predictive distribution\n",
    "\n",
    "    def sample(self, x0=0, step=10):\n",
    "        \"\"\"generate a sample sequence from x0\"\"\"\n",
    "        xt = np.zeros(step, dtype=int) # state sequence\n",
    "        yt = np.zeros(step, dtype=int) # observation sequence\n",
    "        xt[0] = x0\n",
    "        po = self.pobs[:, x0] # prob. of observation\n",
    "        yt[0] = np.random.choice(self.No, p=po) # observe\n",
    "        for t in range(1, step):\n",
    "            ps = self.ptr[:, xt[t-1]]  # prob. of new states\n",
    "            xt[t] = np.random.choice(self.Ns, p=ps) # transit \n",
    "            po = self.pobs[:, xt[t]]   # prob. of observation\n",
    "            yt[t] = np.random.choice(self.No, p=po) # observe \n",
    "        return xt, yt\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"predictive prior by transition model\"\"\"\n",
    "        self.pred = self.ptr @ self.pst\n",
    "    \n",
    "    def update(self, obs):\n",
    "        \"\"\"update posterior by observation\"\"\"\n",
    "        prl = self.pobs[obs]*self.pred # likelihood*prior\n",
    "        self.pst = prl/sum(prl)  #normalize\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"reset state probability\"\"\"\n",
    "        self.pst = np.ones(self.Ns)/self.Ns  # uniform\n",
    "\n",
    "    def step(self, obs):\n",
    "        \"\"\"one step of dynamic bayesian inference\"\"\"\n",
    "        self.predict()\n",
    "        self.update(obs)\n",
    "        return self.pst  # new prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of directed random walk on a ring, like a mouse walking on a circular track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random walk on a ring\n",
    "ns = 6   # ring size\n",
    "ps = 0.3  # shift probability\n",
    "Ptr = np.zeros((ns, ns))  # transition matrix\n",
    "for i in range(ns):\n",
    "    Ptr[i,i] = 1 - ps\n",
    "    Ptr[(i+1)%ns, i] = ps\n",
    "plt.imshow(Ptr)\n",
    "plt.xlabel(\"state\"); plt.ylabel(\"next state\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have three coarse position sensors, which send signal only intermittently, and we want to estimate where the mouse is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blurred intermittent observation model\n",
    "no = 4\n",
    "po = 0.3\n",
    "Pobs = np.zeros((no, ns))  # p(obs|state)\n",
    "Pobs[0,:] = 1 - po  # no information\n",
    "Pobs[1,1] = Pobs[2,3] = Pobs[3,5] = po\n",
    "Pobs[1,0] = Pobs[3,0] = Pobs[1:3,2] = Pobs[2:4,4] = po/2\n",
    "plt.imshow(Pobs)\n",
    "plt.xlabel(\"state\"); plt.ylabel(\"observation\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crate a HMM\n",
    "ring = HMM(Ptr, Pobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample a state trajectory and observations\n",
    "T = 30\n",
    "xt, yt, = ring.sample(1, T)\n",
    "plt.plot(xt)\n",
    "plt.plot(2*yt-1, 'ro');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From such noisy intermittent observations, how can we estimate the state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic Bayesian inference in HMM\n",
    "post = np.zeros((T, ns))  # posterior trajectory\n",
    "ring.reset()\n",
    "for t in range(T):\n",
    "    post[t] = ring.step(yt[t])\n",
    "plt.imshow(post.T, origin='lower')\n",
    "plt.xlabel('t'); plt.ylabel('state');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even when there is no useful sensory input, you can predict the state distribution by the dynamic model.\n",
    "When a sensory input becomes available, prediction is corrected and sharpened.\n",
    "\n",
    "After sensory input, you can also reflect back and consider which previous states were more likely using *forward-backward* algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian sensorimotor processing\n",
    "\n",
    "Our life is full of uncertainty. In sensory perception, we need to cope with noise, delay and occulusion and also overcome fundamental ill-posedness, such as to identify the 3D location of your target from 2D retinal images or sounds to two ears.\n",
    "\n",
    "To find a practical solution to such ill-posed problems, we need to make use of some prior assumptions, such as the light usually comes from the top or objects don't jump abruptly.\n",
    "\n",
    "Bayesian inference provides a principled way for combining any prior knowledge with sensory evidence. Indeed there are several lines of psychological evidence suggesting that humans and animals integrate knowledge from prior experience or multi-modal sensory information as predicted by Bayesian inference (Knill & Pouget 2004, Kording & Wolpert 2004, Doya et al. 2007).\n",
    "\n",
    "% ![Koerding04](figures/Koerding04.png)\n",
    "\n",
    "% While the subject tries to move the cursor to the target, a random shift is introduced to the hand-to-curs mapping. The subjects acquire a prior distribution of the cursor shift and combine that with sensory observations with variable uncertainties, as predicted by Bayesian inference (from Koerding & Wolpert, 2004)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Bayesian computation in the brain\n",
    "\n",
    "How such Bayesian computation realized in the brain? How does the brain represent and manipulate probability distributions?\n",
    "\n",
    "One possibility is that the *receptive field* of a neuron represents a basis function in the sensory space and the activities of a population of neurons represent a probability distribution. This idea is called *probabilistic population code* (Zemel et al. 2004, Ma et al. 2006).\n",
    "\n",
    "The cerebral cortex has a hierarchical organization and bi-directional connections between lower and higher areas originating from specific layers. \n",
    "There have been serveral hypotheses about how such hierarchical recurrent network can realize Bayesian inference, such as belif propagation (Lochmann & Deneve 2011) and variational *free energy* approximation (Friston 2005, 2010; Bogacz 2017).\n",
    "\n",
    ">![Bogacz17](figures/Bogacz17.png)\n",
    ">This tutorial illustrates how variational free-energy approximation of posterior probability works and how such mechanisms might be mapped onto the cortical circuit (from Bobacz 2017).\n",
    "\n",
    "There has been only scarse attempts at directly testing those hypotheses, but a recent two-photon imaging experiment showed the evidence for dynamic Bayesian inference by populations of neurons in the parietal cortex (Funamizu et al. 2016)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* Bishop CM (2006) Pattern Recognition and Machine Learning. Springer. https://www.microsoft.com/en-us/research/people/cmbishop/prml-book/\n",
    "    * Chapter 3: Bayesian linear regression  \n",
    "    * Chapter 8: Graphical models\n",
    "    \n",
    "    \n",
    "### Bayesian sensorimotor integration\n",
    "\n",
    "* Knill DC, Pouget A (2004) The Bayesian brain: the role of uncertainty in neural coding and computation. Trends in neurosciences 27:712-719. https://doi.org/10.1016/j.tins.2004.10.007\n",
    "* Körding KP, Wolpert DM (2004) Bayesian integration in sensorimotor learning. Nature 427:244-247. https://doi.org/10.1038/nature02169\n",
    "* Doya K, Ishii S, Pouget A, Rao R (2007) Bayesian Brain: Probabilistic Approach to Neural Coding and Learning. MIT Press.\n",
    "\n",
    "\n",
    "### Probabilistic population codes\n",
    "\n",
    "* Zemel RS, Dayan P, Pouget A (1998) Probabilistic interpretation of population codes. Neural computation 10:403-430. https://doi.org/10.1162/089976698300017818\n",
    "* Ma WJ, Beck JM, Latham PE, Pouget A (2006) Bayesian inference with probabilistic population codes. Nature neuroscience 9:1432-1438. https://doi.org/10.1038/nn1790\n",
    "\n",
    "\n",
    "### Baysian inference in the cortical circuit\n",
    "\n",
    "* Bogacz R (2017) A tutorial on the free-energy framework for modelling perception and learning. Journal of Mathematical Psychology. 76, 198–211. https://doi.org/10.1016/j.jmp.2015.11.003\n",
    "* Friston K (2005). A theory of cortical responses. Philos Trans R Soc Lond B Biol Sci, 360, 815-36. http://doi.org/10.1098/rstb.2005.1622\n",
    "* Friston K (2010). The free-energy principle: a unified brain theory? Nat Rev Neurosci, 11, 127-38. http://doi.org/10.1038/nrn2787\n",
    "* Lochmann T, Deneve S (2011) Neural processing as causal inference. Current opinion in neurobiology 21:774-781. https://doi.org/10.1016/j.conb.2011.05.018\n",
    "* Funamizu A, Kuhn B, Doya K (2016) Neural substrate of dynamic Bayesian inference in the cerebral cortex. Nature Neuroscience 19:1682-1689. https://doi.org/10.1038/nn.4390"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
