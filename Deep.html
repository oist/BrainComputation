

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Chapter 7: Deep Learning &#8212; Brain Computation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=3ee479438cf8b5e0d341"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Deep';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Chapter 7: Deep Learning: Exercise" href="Deep_Exercise.html" />
    <link rel="prev" title="Bayesian Approaches: Exercise" href="Bayesian_Exercise.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="BrainComputation.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/BC_logo.png" class="logo__image only-light" alt="Brain Computation - Home"/>
    <script>document.write(`<img src="_static/BC_logo.png" class="logo__image only-dark" alt="Brain Computation - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="BrainComputation.html">
                    Brain Computation: A Hands-on Guidebook
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Introduction.html">Chapter 1. Introduction</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="Neurons.html">Chapter 2. Neural Modeling and Analysis</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="Neurons_Exercise.html">Chapter 2. Neural Modeling and Analysis: Exercise</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="Supervised.html">Chapter 3: Supervised Learning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="Supervised_Exercise.html">Supervised Learning: Exercise</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="Reinforcement.html">Chapter 4. Reinforcement Learning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="Reinforcement_Exercise.html">Chapter 4. Reinforcement Learning: Exercise</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="Unsupervised.html">Chapter 5. Unsupervised Learning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="Unsupervised_Exercise.html">Unsupervised Learning: Exercise</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="Bayesian.html">Chatper 6. Bayesian Approaches</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="Bayesian_Exercise.html">Bayesian Approaches: Exercise</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="current reference internal" href="#">Chapter 7: Deep Learning</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="Deep_Exercise.html">Chapter 7: Deep Learning: Exercise</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="Multiple.html">Chapter 8. Multiple Agents</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="Multiple_Exercise.html">Chapter 8. Multiple Agents: Exercise</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="Meta.html">Chapter 9. Meta-Learning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="Meta_Exercise.html">Chapter 9. Meta-Learning: Exercise</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/Deep.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Chapter 7: Deep Learning</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#contents">Contents</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-layer-neural-networks">7.1 Multi-Layer Neural Networks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#universality-of-multi-layer-neural-networks">Universality of multi-layer neural networks</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#recurrent-neural-networks">Recurrent neural networks</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#back-propagation-learning">7.2 Back-Propagation Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-sine-wave">Example: Sine wave</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-nn-for-classification">Deep NN for classification</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-exclusive-or">Example: Exclusive OR</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-donut">Example: Donut</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-class-classification">Multi-class classification</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-generative-models">7.3 Deep Generative Models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#boltzmann-machine">Boltzmann machine</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-generative-networks">Deep generative networks</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#restricted-boltzmann-machines">7.4 Restricted Boltzmann Machines</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-by-contrastive-divergence-cd">Learning by contrastive divergence (CD)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-digits">Example: Digits</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variational-autoencoders-vae">7.5 Variational Autoencoders (VAE)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reparametrization-trick">Reparametrization trick</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-learning-tools-and-pre-trained-weights">7.6 Deep learning tools and pre-trained weights</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visual-cortex-and-covolutional-networks">7.7 Visual cortex and covolutional networks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-and-complex-receptive-fields">Simple and complex receptive fields</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#neocognitron">Neocognitron</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#analyzing-neural-coding-by-trained-deep-networks">Analyzing neural coding by trained deep networks</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="chapter-7-deep-learning">
<h1>Chapter 7: Deep Learning<a class="headerlink" href="#chapter-7-deep-learning" title="Permalink to this heading">#</a></h1>
<div class="math notranslate nohighlight">
\[ % Latex macros
\newcommand{\mat}[1]{\begin{pmatrix} #1 \end{pmatrix}}
\newcommand{\p}[2]{\frac{\partial #1}{\partial #2}}
\renewcommand{\b}[1]{\boldsymbol{#1}}
\newcommand{\w}{\boldsymbol{w}}
\newcommand{\x}{\boldsymbol{x}}
\newcommand{\y}{\boldsymbol{y}}
\newcommand{\z}{\boldsymbol{z}}
\]</div>
<section id="contents">
<h2>Contents<a class="headerlink" href="#contents" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>7.1 Multi-Layer Neural Networks (Bishop, Chater 5)</p>
<ul>
<li><p>Universality of two-layer networks</p></li>
<li><p>Recurrent neural networks</p></li>
</ul>
</li>
<li><p>7.2 Back-Propagation Learning</p>
<ul>
<li><p>Function approximation</p></li>
<li><p>Classification</p></li>
</ul>
</li>
<li><p>7.3 Deep Generative Models</p></li>
<li><p>7.4 Restricted Boltzmann Machines (RBM)</p></li>
<li><p>7.5 Variational Auto-Encoders (VAE)</p></li>
<li><p>7.6 Deep Learning Tools</p>
<ul>
<li><p>Appendix: Deep learning by PyTorch</p></li>
</ul>
</li>
<li><p>7.6 Visual Cortex and Convolutional Networks</p>
<ul>
<li><p>Visual cortex</p></li>
<li><p>Neocognitron</p></li>
<li><p>Deep neural networks for neuroscience</p></li>
</ul>
</li>
</ul>
</section>
<section id="multi-layer-neural-networks">
<h2>7.1 Multi-Layer Neural Networks<a class="headerlink" href="#multi-layer-neural-networks" title="Permalink to this heading">#</a></h2>
<p>In the classic perceptrons and standard linear regression models, the input features <span class="math notranslate nohighlight">\(\b{\phi}(\x)\)</span> were fixed and only the output connection weights <span class="math notranslate nohighlight">\(\w\)</span> were changed by learning to compute the output</p>
<div class="math notranslate nohighlight">
\[
    y = \w^T \b{\phi}(\x).
\]</div>
<p>The capability of such networks is dependent on what features we prepare, either by many randomly connected units in perceptrons or hand-crafted features in conventional patter classification.</p>
<p>An alternative approach is to learn features that suite the required input-output mapping.
Let us consider a two-layer network</p>
<div class="math notranslate nohighlight">
\[
y = w^o_{0} + \sum_{i=1}^M w^o_{i} h_i
\]</div>
<div class="math notranslate nohighlight">
\[
    h_i = g(w^h_{i0} + \sum_{j=1}^D w^h_{ij} x_j),
\]</div>
<p>where <span class="math notranslate nohighlight">\((h_1,...,h_M)\)</span> are the outputs of <em>hidden units</em>.</p>
<p>The <em>activation function</em> <span class="math notranslate nohighlight">\(g(\ )\)</span> is usually the logistic sigmoid function</p>
<div class="math notranslate nohighlight">
\[
    g(u)=\frac{1}{1+e^{-u}}
\]</div>
<p>or the rectified linear unit (ReLU)</p>
<div class="math notranslate nohighlight">
\[
    g(u)=\max(u, 0).
\]</div>
<p>Learning of the hidden unit weights <span class="math notranslate nohighlight">\(w^h_{ij}\)</span> is possible by error gradient descent when the nonlinear function <span class="math notranslate nohighlight">\(g(\ )\)</span> is differentiable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">draw_net</span><span class="p">(</span><span class="n">M</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">offs</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Draw a multi-layer network with M units&quot;&quot;&quot;</span>
    <span class="n">L</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>    <span class="c1"># number of layers</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="p">[</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">M</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">+</span><span class="mi">2</span><span class="p">)[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">L</span><span class="p">)]</span>  <span class="c1"># cell positions</span>
    <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">L</span><span class="p">):</span>  <span class="c1"># from bottom to top layers</span>
        <span class="k">if</span> <span class="n">l</span><span class="o">&lt;</span><span class="n">L</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>  <span class="c1"># cross lines</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">row_stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">Y</span><span class="p">[</span><span class="n">l</span><span class="p">],</span><span class="n">M</span><span class="p">[</span><span class="n">l</span><span class="o">+</span><span class="mi">1</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">Y</span><span class="p">[</span><span class="n">l</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span><span class="n">M</span><span class="p">[</span><span class="n">l</span><span class="p">])))</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>  <span class="c1"># connections</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">Y</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="s1">&#39;ow&#39;</span><span class="p">,</span> <span class="n">ms</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">mec</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>  <span class="c1"># cells</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">list</span><span class="p">:</span>  <span class="c1"># each string</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">Y</span><span class="p">[</span><span class="n">l</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="p">[</span><span class="n">l</span><span class="p">],</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>    <span class="c1"># format with l</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">Y</span><span class="p">[</span><span class="n">l</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">l</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">);</span>
    <span class="k">return</span> <span class="n">Y</span>  <span class="c1"># cell positions</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">draw_net</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;y</span><span class="si">{}</span><span class="s2">&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/ba4cb0a7cdbf45eb24460f76fa3913e01d5af4be92ef5f3302c1d17dd3cb2e53.png" src="_images/ba4cb0a7cdbf45eb24460f76fa3913e01d5af4be92ef5f3302c1d17dd3cb2e53.png" />
</div>
</div>
<section id="universality-of-multi-layer-neural-networks">
<h3>Universality of multi-layer neural networks<a class="headerlink" href="#universality-of-multi-layer-neural-networks" title="Permalink to this heading">#</a></h3>
<p>It has been shown that the two-layer network can approximate any nonlinear function to any desired accuracy using sufficiently large number of hidden units, called <em>universality</em> of multi-layer neural networks.</p>
<p>While just two layers are theoretically enough, it has been shown in applications of multi-layer neural networks that three or more deeper neural networks are more capable in learning complex function approximation or classification tasks.</p>
</section>
<section id="recurrent-neural-networks">
<h3>Recurrent neural networks<a class="headerlink" href="#recurrent-neural-networks" title="Permalink to this heading">#</a></h3>
<p>A discrete-time recurrent neural networks can be considered, by spatial unrolling, as a deep neural network with the same weights shared across all layers.</p>
<p>Thus back-propagation algorithm below can be used for supervised learning of recurrent neural networks.
It is known as <em>back-propatation through time</em>.</p>
<p>As a corollary to the universality of two-layer neural networks, recurrent neural networks can approximate arbitrary dynamical systems.</p>
</section>
</section>
<section id="back-propagation-learning">
<h2>7.2 Back-Propagation Learning<a class="headerlink" href="#back-propagation-learning" title="Permalink to this heading">#</a></h2>
<p>Here we consider a general <span class="math notranslate nohighlight">\(L\)</span>-layer network</p>
<div class="math notranslate nohighlight">
\[
    y^l_i = g^l(w^l_{i0} + \sum_{j=1}^{M^l} w^l_{ij} y^{l-1}_j)
\]</div>
<p>for <span class="math notranslate nohighlight">\(l=(1,...,L)\)</span>.<br />
<span class="math notranslate nohighlight">\(\y^0=\x\)</span> is the input vector and <span class="math notranslate nohighlight">\(\y=\y^L\)</span> is the output vector.</p>
<p>For function approximation, the output function of the last layer is usually linear, i.e. <span class="math notranslate nohighlight">\(g^L(u)=u\)</span>.</p>
<p>Here we consider a <em>stochastic gradient</em> learning, in which we change the weight parameters toward the descending gradient of the error for each input data:</p>
<p>The basic way of online learning is to minimize the output error for each input</p>
<div class="math notranslate nohighlight">
\[
E = \frac{1}{2}||\y - \y^*||^2 = \frac{1}{2}\sum_{i=1}^{M^L}(y^L_i - y^*_i)^2.
\]</div>
<p>The error gradient for the output unit weights are computes as in the linear regression</p>
<div class="math notranslate nohighlight">
\[
\p{E}{w^L_{ij}} = \p{E}{y^L_i}\p{y^L_i}{w^L_{ij}}
  = (y^L_i - y^*_i)y^{L-1}_j. 
\]</div>
<p>By further applying the chain rule of derivatives, the gradient for the hidden unit weights can be computed by following the network top to bottom:</p>
<div class="math notranslate nohighlight">
\[
\p{E}{w^l_{ij}} = \p{E}{y^l_i}\p{y^l_i}{w^l_{ij}}
  = \p{E}{y^l_i} g'^l_i y^{l-1}_j, 
\]</div>
<p>where <span class="math notranslate nohighlight">\(g'^l_i\)</span> is the derivative of the output function. For the logistic sigmoid, it is given as</p>
<div class="math notranslate nohighlight">
\[
g'^l_i = y^l_i(1-y^l_i). 
\]</div>
<p>In the above, <span class="math notranslate nohighlight">\(\p{E}{y^l_i}\)</span> takes the role of an effective error for the <span class="math notranslate nohighlight">\(i\)</span>-th unit in layer <span class="math notranslate nohighlight">\(l\)</span>, and computed iteratively</p>
<div class="math notranslate nohighlight">
\[
\p{E}{y^l_i} = \sum_{k=1}^{M^{l+1}}\p{E}{y^{l+1}_k}g'^{l+1}_k w^{l+1}_{ki}. 
\]</div>
<p>In the example below, the red lines show the propagation of errors from the two output units to a unit in layer 2.<br />
The blue lines show the propagation of errors through layer 2 to one unit in layer 1.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Y</span> <span class="o">=</span> <span class="n">draw_net</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;y</span><span class="si">{}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
<span class="c1"># to layer 2</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">row_stack</span><span class="p">((</span><span class="n">Y</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">Y</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span><span class="mi">2</span><span class="p">)))</span><span class="o">+</span><span class="mf">0.01</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span>
<span class="c1"># to layer 1</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">row_stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">Y</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span><span class="mi">3</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">Y</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span><span class="mi">2</span><span class="p">))),</span> <span class="s2">&quot;b&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">row_stack</span><span class="p">((</span><span class="n">Y</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">Y</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span><span class="mi">3</span><span class="p">))),</span> <span class="s2">&quot;b&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/0503a8ad6c08e4c0a7f46a7004574bc7afc3e60296145b9815ff37ba9dd3653d.png" src="_images/0503a8ad6c08e4c0a7f46a7004574bc7afc3e60296145b9815ff37ba9dd3653d.png" />
</div>
</div>
<p>Using these error gradients, all the weights can be updated by</p>
<div class="math notranslate nohighlight">
\[
    \Delta w^l_{ij} = - \alpha \p{E}{w^l_{ij}} 
\]</div>
<p>where <span class="math notranslate nohighlight">\(\alpha&gt;0\)</span> is a learning rate paramter.</p>
<p>This is called <em>error back-propagation</em> learning algorithm.</p>
<p>Below is a sample implementation of back-propagation with sigmoid hidden units and linear output units.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">DNN</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Simple class for a deep neural network&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">winit</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create a new netowrk: units:list of numbers of units&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">units</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span>   <span class="c1"># number of layers (excluding input)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">M</span> <span class="o">=</span> <span class="n">units</span>  <span class="c1"># numbers of units in layers</span>
        <span class="c1"># output and error vectors: layer 0 to L</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Y</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">M</span><span class="p">[</span><span class="n">l</span><span class="p">])</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">err</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">M</span><span class="p">[</span><span class="n">l</span><span class="p">])</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
        <span class="c1"># initialize small random weights and bias</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="n">winit</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">M</span><span class="p">[</span><span class="n">l</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">M</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">)]</span>
    
    <span class="k">def</span> <span class="nf">act</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;activation function y=g(u)&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">u</span><span class="p">))</span>  <span class="c1"># logistic sigmoid</span>
    <span class="k">def</span> <span class="nf">dact</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;derivative of activation function dy/du|y&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">y</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">y</span><span class="p">)</span>     <span class="c1"># dy/du</span>

    <span class="k">def</span> <span class="nf">output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;activation function for the output unit&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">u</span>  <span class="c1"># identity</span>
    <span class="k">def</span> <span class="nf">outerror</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">yt</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;output error based on negative log likelihood&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">y</span><span class="o">-</span><span class="n">yt</span>  <span class="c1"># difference</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute the output&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># input vector</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">):</span>
            <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="n">l</span><span class="p">][:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="n">l</span><span class="p">][:,</span><span class="mi">1</span><span class="p">:]</span><span class="nd">@self</span><span class="o">.</span><span class="n">Y</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>  <span class="c1"># include bias</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">[</span><span class="n">l</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">z</span><span class="p">)</span> <span class="k">if</span> <span class="n">l</span><span class="o">+</span><span class="mi">1</span><span class="o">==</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>  <span class="c1"># linear output</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>  <span class="c1"># last layer, as scalar if 1D</span>
    
    <span class="k">def</span> <span class="nf">backprop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Error backpropagation learning&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>  <span class="c1"># from top to bottom</span>
            <span class="k">if</span> <span class="n">l</span><span class="o">==</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">:</span>  <span class="c1"># output layer</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">err</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">outerror</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">[</span><span class="n">l</span><span class="p">],</span> <span class="n">target</span><span class="p">)</span>  <span class="c1"># output error</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># error propapation from the layer above</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">err</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">err</span><span class="p">[</span><span class="n">l</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="nd">@self</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="n">l</span><span class="p">][:,</span><span class="mi">1</span><span class="p">:]</span> <span class="c1"># exclude bias</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">err</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dact</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">[</span><span class="n">l</span><span class="p">])</span>  <span class="c1"># error before the gain</span>
            <span class="c1"># error gradient</span>
            <span class="n">dW</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">err</span><span class="p">[</span><span class="n">l</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(([</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">[</span><span class="n">l</span><span class="o">-</span><span class="mi">1</span><span class="p">])))</span>
            <span class="c1"># update weights by the error gradient</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="n">l</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-=</span> <span class="n">alpha</span><span class="o">*</span><span class="n">dW</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">err</span><span class="p">[</span><span class="o">-</span><span class="n">l</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">err</span><span class="p">[</span><span class="o">-</span><span class="n">l</span><span class="p">])</span>  <span class="c1"># sum of squared error</span>
    
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;train by a dataset&quot;&quot;&quot;</span>
        <span class="n">N</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># data size</span>
        <span class="k">if</span> <span class="n">repeat</span><span class="o">&gt;</span><span class="mi">1</span><span class="p">:</span>
            <span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">repeat</span><span class="p">)</span>  <span class="c1"># record of mean square errors</span>
            <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">repeat</span><span class="p">):</span>
                <span class="n">sse</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">mse</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sse</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">mse</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>  <span class="c1"># record of sum square errors</span>
            <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
                <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="n">n</span><span class="p">])</span>
                <span class="n">sse</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backprop</span><span class="p">(</span><span class="n">targets</span><span class="p">[</span><span class="n">n</span><span class="p">],</span> <span class="n">alpha</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">sse</span>
</pre></div>
</div>
</div>
</div>
<section id="example-sine-wave">
<h3>Example: Sine wave<a class="headerlink" href="#example-sine-wave" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># sine wave dataset</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mf">0.05</span>  <span class="c1"># noise</span>
<span class="n">xr</span> <span class="o">=</span> <span class="mi">6</span>  <span class="c1"># range of x</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="n">xr</span><span class="p">,</span> <span class="n">xr</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span> <span class="c1">#.reshape((N,1))</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">N</span><span class="p">)</span> <span class="c1">#(N,1))</span>
<span class="n">Np</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># data for test/plot</span>
<span class="n">Xp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="n">xr</span><span class="p">,</span> <span class="n">xr</span><span class="p">,</span> <span class="n">Np</span><span class="p">)</span> <span class="c1">#.reshape((N,1))</span>
<span class="n">fp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">Xp</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Xp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="s2">&quot;g&quot;</span><span class="p">)</span>  <span class="c1"># target</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="s2">&quot;ro&quot;</span><span class="p">)</span>   <span class="c1"># training data</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;training data&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/df979391e5aea8d0ac5d4afa3c9c65f2f04dad5f7bd280bf5588de5852beb283.png" src="_images/df979391e5aea8d0ac5d4afa3c9c65f2f04dad5f7bd280bf5588de5852beb283.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a network</span>
<span class="n">M</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">dn</span> <span class="o">=</span> <span class="n">DNN</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">winit</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Visualize hidden and output units</span>
<span class="n">yp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">Np</span><span class="p">)</span>
<span class="n">hp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">Np</span><span class="p">,</span> <span class="n">dn</span><span class="o">.</span><span class="n">M</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Np</span><span class="p">):</span>
    <span class="n">yp</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">dn</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">Xp</span><span class="p">[</span><span class="n">n</span><span class="p">])</span>
    <span class="n">hp</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">dn</span><span class="o">.</span><span class="n">Y</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># hidden units</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Xp</span><span class="p">,</span> <span class="n">yp</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">)</span>  <span class="c1"># output unit</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Xp</span><span class="p">,</span> <span class="n">hp</span><span class="p">)</span>  <span class="c1"># hidden units</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;h, y&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;hidden &amp; output units&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/c78ad373dbd8297617454d76c0cffdf4e5ab0e1f7d68d2ae37ee8e00768fe2ce.png" src="_images/c78ad373dbd8297617454d76c0cffdf4e5ab0e1f7d68d2ae37ee8e00768fe2ce.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train with the data</span>
<span class="n">mse</span> <span class="o">=</span> <span class="n">dn</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="c1">#print(dn.W)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mse =&quot;</span><span class="p">,</span> <span class="n">mse</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>  <span class="c1"># final mse</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">mse</span><span class="p">);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;iteration&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;mse&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;learning curve&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>mse = 0.3856215717053344
</pre></div>
</div>
<img alt="_images/4b458f5c7b51c258b9ccc42cfff00a6d32b7e828c57e63f942bcf1bb35712ec0.png" src="_images/4b458f5c7b51c258b9ccc42cfff00a6d32b7e828c57e63f942bcf1bb35712ec0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># see fitting</span>
<span class="n">yp</span> <span class="o">=</span> <span class="p">[</span><span class="n">dn</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">Xp</span><span class="p">[</span><span class="n">n</span><span class="p">])</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Np</span><span class="p">)]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Xp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="s2">&quot;g&quot;</span><span class="p">)</span>  <span class="c1"># target</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="s2">&quot;r.&quot;</span><span class="p">)</span>   <span class="c1"># training data</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Xp</span><span class="p">,</span> <span class="n">yp</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">)</span>  <span class="c1"># testing</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;testing&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/9c9ad7b0c3f775445cb3160058eee356a427156b69a471c603c7f5085c6d494a.png" src="_images/9c9ad7b0c3f775445cb3160058eee356a427156b69a471c603c7f5085c6d494a.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Visualize hidden and output units</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Np</span><span class="p">):</span>
    <span class="n">yp</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">dn</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">Xp</span><span class="p">[</span><span class="n">n</span><span class="p">])</span>
    <span class="n">hp</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">dn</span><span class="o">.</span><span class="n">Y</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># hidden units</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Xp</span><span class="p">,</span> <span class="n">yp</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">)</span>  <span class="c1"># output unit</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Xp</span><span class="p">,</span> <span class="n">hp</span><span class="p">)</span>  <span class="c1"># hidden units</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;h, y&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;hidden &amp; output units&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/5c8dfb6ff5361ed9d3e043e5d8bc85a85b934691c50072ffe156eaa97c13ecac.png" src="_images/5c8dfb6ff5361ed9d3e043e5d8bc85a85b934691c50072ffe156eaa97c13ecac.png" />
</div>
</div>
</section>
<section id="deep-nn-for-classification">
<h3>Deep NN for classification<a class="headerlink" href="#deep-nn-for-classification" title="Permalink to this heading">#</a></h3>
<p>For binary classification, the target output is <span class="math notranslate nohighlight">\(y^*\in\{0,1\}\)</span> and we use a network with sigmoid output to predict the probablity</p>
<div class="math notranslate nohighlight">
\[
p(y^*=1)=y=\sigma(u)=\frac{1}{1+e^{-u}}.
\]</div>
<p>The output error calculated as negative log likelihood</p>
<div class="math notranslate nohighlight">
\[
E = -y^*\log y -(1-y^*)\log(1-y) 
\]</div>
<p>is called <em>cross entropy error</em>.</p>
<p>Its gradient with respect to the output <span class="math notranslate nohighlight">\(y\)</span> is</p>
<div class="math notranslate nohighlight">
\[
\p{E}{y} = -\frac{y^*}{y} + \frac{1-y^*}{1-y}. 
\]</div>
<p>The gradient with respect to the input sum <span class="math notranslate nohighlight">\(z\)</span> is</p>
<div class="math notranslate nohighlight">
\[
\p{E}{z} = \p{E}{y}\p{y}{z}
   = (-\frac{y^*}{y} + \frac{1-y^*}{1-y}) y(1-y) 
\]</div>
<div class="math notranslate nohighlight">
\[
= -y^*(1-y) + (1-y^*)y = y - y^*. 
\]</div>
<p>Below is a modified class for binary classification.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">DNNb</span><span class="p">(</span><span class="n">DNN</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A deep neural network for classification&quot;&quot;&quot;</span>
    <span class="c1"># override the output function and error</span>
    <span class="k">def</span> <span class="nf">output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;activation function for the output unit&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>  <span class="c1"># sigmoid</span>
    <span class="c1"># the output error dE/dz stays the same</span>
</pre></div>
</div>
</div>
</div>
<section id="example-exclusive-or">
<h4>Example: Exclusive OR<a class="headerlink" href="#example-exclusive-or" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ExOr data</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">4</span>
<span class="c1">#sigma = 0.1  # input spread</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]])</span>  <span class="c1"># four corners</span>
<span class="n">yt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>  <span class="c1"># ExOr</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">yt</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;x1&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;x2&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;square&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;training data&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/60b265fe7a2455d35170ce08b0c518fd293ab1d1e19129140648c3879c331255.png" src="_images/60b265fe7a2455d35170ce08b0c518fd293ab1d1e19129140648c3879c331255.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a network</span>
<span class="n">M</span> <span class="o">=</span> <span class="mi">5</span>  <span class="c1"># hidden units</span>
<span class="n">dn</span> <span class="o">=</span> <span class="n">DNNb</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">winit</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># data for test/plot</span>
<span class="n">Np</span> <span class="o">=</span> <span class="mi">10</span>  
<span class="n">xp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">Np</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Output</span>
<span class="n">yp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">dn</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">xp1</span><span class="p">,</span><span class="n">xp2</span><span class="p">]))</span> <span class="k">for</span> <span class="n">xp2</span> <span class="ow">in</span> <span class="n">xp</span><span class="p">]</span> <span class="k">for</span> <span class="n">xp1</span> <span class="ow">in</span> <span class="n">xp</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">pcolormesh</span><span class="p">(</span><span class="n">xp</span><span class="p">,</span> <span class="n">xp</span><span class="p">,</span> <span class="n">yp</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;x1&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;x2&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;square&#39;</span><span class="p">);</span>
<span class="c1"># Hidden unit activation boundaries</span>
<span class="c1"># w0+w1*x1+w2*x2=0 -&gt; x2=-(w0+w1*x1)/w2</span>
<span class="n">h0</span> <span class="o">=</span> <span class="o">-</span><span class="n">dn</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">dn</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">2</span><span class="p">]</span>
<span class="n">h1</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">dn</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">dn</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="n">dn</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">2</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">yt</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">row_stack</span><span class="p">((</span><span class="n">h0</span><span class="p">,</span><span class="n">h1</span><span class="p">)));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/41789758f4888fde26346cbab028002ca1ad5fbec53bb60e2e7518b0eba7dd7a.png" src="_images/41789758f4888fde26346cbab028002ca1ad5fbec53bb60e2e7518b0eba7dd7a.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train with the data</span>
<span class="n">mse</span> <span class="o">=</span> <span class="n">dn</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">yt</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="mi">3000</span><span class="p">)</span>
<span class="c1">#print(dn.W)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mse =&quot;</span><span class="p">,</span> <span class="n">mse</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>  <span class="c1"># final mse</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">mse</span><span class="p">);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;iteration&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;mse&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;learning curve&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>mse = 0.0008265949024898799
</pre></div>
</div>
<img alt="_images/b8d261fde72df28ef6aa20ba39d7a8d9e25171e94eac359e3f3f52b991cfc50e.png" src="_images/b8d261fde72df28ef6aa20ba39d7a8d9e25171e94eac359e3f3f52b991cfc50e.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Output</span>
<span class="n">yp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">dn</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">xp1</span><span class="p">,</span><span class="n">xp2</span><span class="p">]))</span> <span class="k">for</span> <span class="n">xp2</span> <span class="ow">in</span> <span class="n">xp</span><span class="p">]</span> <span class="k">for</span> <span class="n">xp1</span> <span class="ow">in</span> <span class="n">xp</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">pcolormesh</span><span class="p">(</span><span class="n">xp</span><span class="p">,</span> <span class="n">xp</span><span class="p">,</span> <span class="n">yp</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;x1&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;x2&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;square&#39;</span><span class="p">);</span>
<span class="c1"># Hidden unit activation boundaries</span>
<span class="c1"># w0+w1*x1+w2*x2=0 -&gt; x2=-(w0+w1*x1)/w2</span>
<span class="n">h0</span> <span class="o">=</span> <span class="o">-</span><span class="n">dn</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">dn</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">2</span><span class="p">]</span>
<span class="n">h1</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">dn</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">dn</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="n">dn</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">2</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">yt</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">row_stack</span><span class="p">((</span><span class="n">h0</span><span class="p">,</span><span class="n">h1</span><span class="p">)));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/ca5ce4de8072630f715dbae808baaa66d7d64f933e0d1e919c1805f3f8b3006a.png" src="_images/ca5ce4de8072630f715dbae808baaa66d7d64f933e0d1e919c1805f3f8b3006a.png" />
</div>
</div>
</section>
<section id="example-donut">
<h4>Example: Donut<a class="headerlink" href="#example-donut" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">xr</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="n">xr</span><span class="p">,</span> <span class="n">xr</span><span class="p">,</span> <span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">yt</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span><span class="o">&gt;</span><span class="mi">4</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span><span class="o">&lt;</span><span class="mi">9</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">yt</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;x1&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;x2&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;square&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;training data&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3d49a639eba03ffbcebda8634da243e46d732f38c20ff8fea93662e34b006e4c.png" src="_images/3d49a639eba03ffbcebda8634da243e46d732f38c20ff8fea93662e34b006e4c.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a network</span>
<span class="n">M</span> <span class="o">=</span> <span class="mi">10</span>  <span class="c1"># hidden units</span>
<span class="n">dn</span> <span class="o">=</span> <span class="n">DNNb</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">winit</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># data for test/plot</span>
<span class="n">Np</span> <span class="o">=</span> <span class="mi">20</span>  
<span class="n">xp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="n">xr</span><span class="p">,</span> <span class="n">xr</span><span class="p">,</span> <span class="n">Np</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Output</span>
<span class="n">yp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">dn</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">xp1</span><span class="p">,</span><span class="n">xp2</span><span class="p">]))</span> <span class="k">for</span> <span class="n">xp2</span> <span class="ow">in</span> <span class="n">xp</span><span class="p">]</span> <span class="k">for</span> <span class="n">xp1</span> <span class="ow">in</span> <span class="n">xp</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">pcolormesh</span><span class="p">(</span><span class="n">xp</span><span class="p">,</span> <span class="n">xp</span><span class="p">,</span> <span class="n">yp</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;x1&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;x2&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;square&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="c1"># Hidden unit activation boundary</span>
<span class="c1"># w0+w1*x1+w2*x2=0 -&gt; x2=-(w0+w1*x1)/w2</span>
<span class="n">h0</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">dn</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="n">xr</span><span class="o">*</span><span class="n">dn</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="n">dn</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">2</span><span class="p">]</span>
<span class="n">h1</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">dn</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">xr</span><span class="o">*</span><span class="n">dn</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="n">dn</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">2</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="n">xr</span><span class="p">,</span><span class="n">xr</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">row_stack</span><span class="p">((</span><span class="n">h0</span><span class="p">,</span><span class="n">h1</span><span class="p">)))</span>
<span class="c1"># training data</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">yt</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/1a7f49739da149cab7e859e3d3c71d86905c17e3c7477ba5cb2ad7836c870983.png" src="_images/1a7f49739da149cab7e859e3d3c71d86905c17e3c7477ba5cb2ad7836c870983.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train with the data</span>
<span class="n">mse</span> <span class="o">=</span> <span class="n">dn</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">yt</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="mi">3000</span><span class="p">)</span>
<span class="c1">#print(dn.W)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mse =&quot;</span><span class="p">,</span> <span class="n">mse</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>  <span class="c1"># final mse</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">mse</span><span class="p">);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;iteration&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;mse&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;learning curve&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>mse = 0.04707310495898387
</pre></div>
</div>
<img alt="_images/54859a9814bba27d1be0b3e7726238f72e7af043e33a6a07b5469c033142fa34.png" src="_images/54859a9814bba27d1be0b3e7726238f72e7af043e33a6a07b5469c033142fa34.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Output</span>
<span class="n">yp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">dn</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">xp1</span><span class="p">,</span><span class="n">xp2</span><span class="p">]))</span> <span class="k">for</span> <span class="n">xp2</span> <span class="ow">in</span> <span class="n">xp</span><span class="p">]</span> <span class="k">for</span> <span class="n">xp1</span> <span class="ow">in</span> <span class="n">xp</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">pcolormesh</span><span class="p">(</span><span class="n">xp</span><span class="p">,</span> <span class="n">xp</span><span class="p">,</span> <span class="n">yp</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;x1&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;x2&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;square&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="c1"># Hidden unit activation boundary</span>
<span class="c1"># w0+w1*x1+w2*x2=0 -&gt; x2=-(w0+w1*x1)/w2</span>
<span class="n">h0</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">dn</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="n">xr</span><span class="o">*</span><span class="n">dn</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="n">dn</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">2</span><span class="p">]</span>
<span class="n">h1</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">dn</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">xr</span><span class="o">*</span><span class="n">dn</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="n">dn</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">2</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="n">xr</span><span class="p">,</span><span class="n">xr</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">row_stack</span><span class="p">((</span><span class="n">h0</span><span class="p">,</span><span class="n">h1</span><span class="p">)))</span>
<span class="c1"># training data</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">yt</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/2a7864fe1194bf17226ec9531842601928df3013594346416ff04869fac0bc56.png" src="_images/2a7864fe1194bf17226ec9531842601928df3013594346416ff04869fac0bc56.png" />
</div>
</div>
</section>
</section>
<section id="multi-class-classification">
<h3>Multi-class classification<a class="headerlink" href="#multi-class-classification" title="Permalink to this heading">#</a></h3>
<p>For multiple classes <span class="math notranslate nohighlight">\(K\)</span>, the target output is <span class="math notranslate nohighlight">\(\y^*=(y^*_1,...,y^*_K)\)</span> where only one of the component <span class="math notranslate nohighlight">\(y^*_k=1\)</span> and others are zero.</p>
<p>In this case the standard activation function is the <em>softmax</em> function</p>
<div class="math notranslate nohighlight">
\[ y_k = p(y^*_k=1) = \mbox{softmax}_k(\b{u}) = \frac{e^{u_k}}{\sum_{j=1}^K e^{u_j}} \]</div>
<p>and the cross entropy error is given as</p>
<div class="math notranslate nohighlight">
\[ E = - \sum_{k=1}^K y^*_k \log y_k \]</div>
<p>Its gradient with respect to the output <span class="math notranslate nohighlight">\(y_k\)</span> is</p>
<div class="math notranslate nohighlight">
\[ \p{E}{y_k} = -\frac{y^*_k}{y_k} \]</div>
<p>The derivative of the softmax function is</p>
<div class="math notranslate nohighlight">
\[ \p{y_k}{u_i} = \delta_{ki}\frac{e^{u_k}}{\sum_{j=1}^K e^{u_j}}
- \frac{e^{u_k}e^{u_i}}{(\sum_{j=1}^K e^{u_j})^2} 
 = \delta_{ki}y_k + y_k y_i \]</div>
<p>Thus the error gradient with respect to the input sum <span class="math notranslate nohighlight">\(u_i\)</span> is</p>
<div class="math notranslate nohighlight">
\[ \p{E}{u_i} = \sum_{k=1}^K \p{E}{y_k}\p{y_k}{u_i}
   = \sum_{k=1}^K -\frac{y^*_k}{y_k}(\delta_{ki}y_k - y_k y_i) \]</div>
<div class="math notranslate nohighlight">
\[ = \sum_{k=1}^K -y^*_k(\delta_{ki} + y_i) 
   = y_i - y^*_i, \]</div>
<p>same as in the case of linear output and sigmoid output.</p>
</section>
</section>
<section id="deep-generative-models">
<h2>7.3 Deep Generative Models<a class="headerlink" href="#deep-generative-models" title="Permalink to this heading">#</a></h2>
<p>In back-propagation, we considered input-output mapping</p>
<div class="math notranslate nohighlight">
\[
    \y = f(\x)
\]</div>
<p>to approximate the target output <span class="math notranslate nohighlight">\(\y^*\)</span>.</p>
<p>An opposite approach is <em>generative models</em></p>
<div class="math notranslate nohighlight">
\[
    \x \sim g(\x|\z)
\]</div>
<p>which assumes that the data <span class="math notranslate nohighlight">\(\x\)</span> are produced by a hierarchical probabilistic model with the higher level <em>latent variable</em> <span class="math notranslate nohighlight">\(\z\)</span>, such as the class labels or low-dimensional parameter space.
For a given input <span class="math notranslate nohighlight">\(\x\)</span>, we consider what is the latent variable behind the data, such as the MAP estimate</p>
<div class="math notranslate nohighlight">
\[
    \y = \arg\max_\z g(\x|\z)
\]</div>
<section id="boltzmann-machine">
<h3>Boltzmann machine<a class="headerlink" href="#boltzmann-machine" title="Permalink to this heading">#</a></h3>
<p>The Boltzmann machine is a stochastic binary recurrent network consisting of <em>visible</em> and <em>hidden</em> units. The joint distribution over the visible and hidden units is given by the <em>energy function</em>.</p>
<p>With sufficient number of hidden units and setting of the connection weights, Boltzmann machines can represent arbitrary distributions over visible units. However, learning of Boltzmann machine is <em>intractable</em>, requiring computation of posterior probabilities for exponentially large number of states.</p>
<p>The <em>restricted Bolzmann machine (RBM)</em> is a Boltzmann machine having a layered structure, with connections only between subsequent layers and no connections within each layer.
As described below, RBM can be trained efficiently by an algorithm called <em>contrastive divergence</em>.</p>
</section>
<section id="deep-generative-networks">
<h3>Deep generative networks<a class="headerlink" href="#deep-generative-networks" title="Permalink to this heading">#</a></h3>
<p>Early deep generative models were produced by stacking RBMs and train them from the bottom to top. Examples are <em>deep belief networks (DBN)</em> and <em>deep Boltzmann machine (DBM)</em>.
They were used for pre-training of deep networks for pattern classification, although recently simple back-propagation without pre-training has become popular (Salakhutdinov &amp; Hinton 2012).</p>
<p>Currently <em>variational auto encoders (VAE)</em> and <em>generative adversarial networks (GAN)</em> are the most popular and successful architectures in image generation.</p>
<p>VAE is composed of two networks, a differentiable <em>generator</em> network that converts hidden variable <span class="math notranslate nohighlight">\(\b{z}\)</span> to data <span class="math notranslate nohighlight">\(\x\)</span>, and an <em>encoder</em> network that learns to approximate the posterior probability of the hidden variables <span class="math notranslate nohighlight">\(p(\b{z}|\x)\)</span>.</p>
<p>GAN also uses a differentiable generator network but is coupled with a <em>discriminator</em> network that learns to distinguish the real data and the data produced by the generator.</p>
</section>
</section>
<section id="restricted-boltzmann-machines">
<h2>7.4 Restricted Boltzmann Machines<a class="headerlink" href="#restricted-boltzmann-machines" title="Permalink to this heading">#</a></h2>
<p>A restricted Boltzmann machine (RBM) is a two-layer network with undirected connections between visible and hidden layers, with no connections among visible or hidden layers. This produces conditional independence of distributions of hidden units given visible units, and visible units given hidden units, which allows efficient learning (Hinton 2010).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">draw_net</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;visible&quot;</span><span class="p">,</span> <span class="s2">&quot;hidden&quot;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Restricted Boltzmann machine (RBM)&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/8540f09b99e6827caaa0401db81c92d3bfb25c8d1a2b0493110a22f8e0e4cfed.png" src="_images/8540f09b99e6827caaa0401db81c92d3bfb25c8d1a2b0493110a22f8e0e4cfed.png" />
</div>
</div>
<p>Here we represent the state of visible units by <span class="math notranslate nohighlight">\(\b{v}\in\{0,1\}^{M_v}\)</span> and hidden units by <span class="math notranslate nohighlight">\(\b{h}\in\{0,1\}^{M_h}\)</span>.
For the connection weights <span class="math notranslate nohighlight">\(W\in R^{M_v\times M_h}\)</span> and the bias inputs <span class="math notranslate nohighlight">\(\b{b}\)</span> and <span class="math notranslate nohighlight">\(\b{c}\)</span> for visible and hidden units, respectively,
the <em>energy</em> function of the RBM is defined as</p>
<div class="math notranslate nohighlight">
\[ E(\b{v},\b{h}) = \b{b}^T\b{v}  \b{c}^T\b{h}  \b{v}^T W\b{h}. \]</div>
<p>The joint distribution of the states of the visible and and hidden units are given by</p>
<div class="math notranslate nohighlight">
\[ p(\b{v},\b{h}) = \frac{1}{Z} e^{E(\b{v},\b{h})}, \]</div>
<p>where <span class="math notranslate nohighlight">\(Z\)</span> is the normalizing constant called <em>partition function</em>, given by</p>
<div class="math notranslate nohighlight">
\[ Z = \sum_\b{v}\sum_\b{h} e^{E(\b{v},\b{h})}. \]</div>
<p>The marginal distribution for the visibile units is given by summing over all states of hidden units</p>
<div class="math notranslate nohighlight">
\[ p(\b{v}) = \frac{1}{Z}\sum_\b{h} e^{E(\b{v},\b{h})}. \]</div>
<p>As the analytic form of maximul likelihood estimate is not available, we apply the stochastic gradient with respect to the parameters <span class="math notranslate nohighlight">\(\theta=(W,\b{b},\b{c})\)</span> .
The gradient of the log probability of the energy-based model is given by</p>
<div class="math notranslate nohighlight">
\[ \p{\log p(\b{v},\b{h}|\theta)}{\theta} 
 = -\p{E(\b{v},\b{h};\theta)}{\theta} 
 + \sum_{\b{v}}\sum_{\b{h}}p(\b{v},\b{h})\p{E(\b{v},\b{h};\theta)}{\theta}. \]</div>
<p>Thus the log likelihood for the visible unit state <span class="math notranslate nohighlight">\(\b{v}_n\)</span> <span class="math notranslate nohighlight">\((n=1,...,N)\)</span> is given as</p>
<div class="math notranslate nohighlight">
\[ \p{\log p(\b{v}_n|\theta)}{\theta} 
 = -\sum_\b{h}p(\b{h}|\b{v}_n)\p{E(\b{v}_n,\b{h};\theta)}{\theta} 
 + \sum_{\b{v}}\sum_{\b{h}}p(\b{v},\b{h})\p{E(\b{v},\b{h};\theta)}{\theta} \]</div>
<p>The first term is data-dependent statistics and the second term is data-independent statistics coming from the partition function.</p>
<section id="learning-by-contrastive-divergence-cd">
<h3>Learning by contrastive divergence (CD)<a class="headerlink" href="#learning-by-contrastive-divergence-cd" title="Permalink to this heading">#</a></h3>
<p>Because RBM has no connections between hidden units, the probability of the hidden unit states is conditionally independent given the visible unit state</p>
<div class="math notranslate nohighlight">
\[ p(\b{h}|\b{v}) = \prod_{j=1}^{M_h} p(h_j|\b{v}). \]</div>
<p>The probability for each hidden unit to be active is given by the sigmoid function of its input</p>
<div class="math notranslate nohighlight">
\[ p(h_j=1|\b{v}) = \sigma(c_j + \sum_{i=1}^{M_v}v_i w_{ij}).\]</div>
<p>This allows evaluation of the first term of the log likelihood gradient by simple sampling.</p>
<p>Similarly, the probability for the visible units is also conditionally independent given the hidden units and each visible unit satate is given by</p>
<div class="math notranslate nohighlight">
\[ p(v_i=1|\b{h}) = \sigma(b_i + \sum_{j=1}^{N_h}w_{ij}h_j). \]</div>
<p>In order to evaluate the second term, we have to take samples from the unconstrained model dynamics. The <em>contrastive divergence</em> method takes a crude approximation of the model distribution but has been shown to perform surprizingly well.</p>
<p>First we set the initial state of the visible units by a sample <span class="math notranslate nohighlight">\(\b{v}^0=\b{v}_n\)</span>. Then we repeatedly sample hidden units</p>
<div class="math notranslate nohighlight">
\[ \b{h}^k \sim p(\b{h}|\b{v}^k) \]</div>
<p>and the visible units</p>
<div class="math notranslate nohighlight">
\[ \b{v}^{k+1} \sim p(\b{v}|\b{h}^k) \]</div>
<p>for <span class="math notranslate nohighlight">\(K\)</span> times.</p>
<p>The unconstrained joint distribution is approximated by</p>
<div class="math notranslate nohighlight">
\[ p_{CD_K}(\b{v},\b{h})=\delta(\b{v}-\b{v}_n^K)p(\b{h}|\b{v}_n^K), \]</div>
<p>where <span class="math notranslate nohighlight">\(\delta(\x)\)</span> is a single point distribution at <span class="math notranslate nohighlight">\(\x=0\)</span>.</p>
<p>The parameters are updated with a learning rate parameter <span class="math notranslate nohighlight">\(\alpha\)</span> as follows.</p>
<div class="math notranslate nohighlight">
\[ \Delta W = \alpha [\b{v}_n p(\b{h}|\b{v}_n) - \b{v}_n^K p(\b{h}|\b{v}_n^K)]  \]</div>
<div class="math notranslate nohighlight">
\[ \Delta\b{b} = \alpha [\b{v}_n - \b{v}_n^K]  \]</div>
<div class="math notranslate nohighlight">
\[ \Delta\b{c} = \alpha [p(\b{h}|\b{v}_n) - p(\b{h}|\b{v}_n^K)]. \]</div>
<p>This contrastive divergence method has been shown to work well even for small <span class="math notranslate nohighlight">\(K=1\)</span>.
Instead of this stochastic gradient for each data, <em>mini-batch</em> method to average gradients for tens of data points are often used.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># RBM</span>
<span class="k">class</span> <span class="nc">RBM</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Restricted Boltzmann machine [Mv,Mh]&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="n">winit</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create a new RBM: units:list of numbers of units&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Mv</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Mh</span> <span class="o">=</span> <span class="n">units</span>  <span class="c1"># number of visible/hidden units</span>
        <span class="c1"># visible and hidden units</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Mv</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Mh</span><span class="p">)</span>
        <span class="c1"># initialize small random weights and bias</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="n">winit</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Mv</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">Mh</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="n">winit</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">Mv</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="n">winit</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">Mh</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">phv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;p(h|v)&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">c</span> <span class="o">+</span> <span class="n">v</span><span class="nd">@self</span><span class="o">.</span><span class="n">W</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">pvh</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;p(v|h)&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="nd">@h</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vin</span><span class="p">,</span> <span class="n">K</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;sample hidden and visible units K time&quot;&quot;&quot;</span>
        <span class="n">pv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">K</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">Mv</span><span class="p">))</span>  <span class="c1"># probabilities</span>
        <span class="n">ph</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">K</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">Mh</span><span class="p">))</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">K</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">Mv</span><span class="p">))</span>  <span class="c1"># binary samples</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">K</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">Mh</span><span class="p">))</span>
        <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">pv</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">vin</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
            <span class="n">ph</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">phv</span><span class="p">(</span><span class="n">v</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
            <span class="n">h</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Mh</span><span class="p">)</span><span class="o">&lt;</span><span class="n">ph</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
            <span class="n">pv</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pvh</span><span class="p">(</span><span class="n">h</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
            <span class="n">v</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Mv</span><span class="p">)</span><span class="o">&lt;</span><span class="n">pv</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">ph</span><span class="p">[</span><span class="n">K</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">phv</span><span class="p">(</span><span class="n">v</span><span class="p">[</span><span class="n">K</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">ph</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">pv</span><span class="p">,</span> <span class="n">v</span>
    
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">K</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;train with data V=[v1,...,vN]&quot;&quot;&quot;</span>
        <span class="n">N</span> <span class="o">=</span> <span class="n">V</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># data size</span>
        <span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">T</span><span class="p">)</span>  <span class="c1"># record of mean square errors</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span> <span class="c1"># repeat</span>
            <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>  <span class="c1"># simple SGD without minibatch</span>
                <span class="n">ph</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">pv</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">V</span><span class="p">[</span><span class="n">n</span><span class="p">],</span> <span class="n">K</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">+=</span> <span class="n">alpha</span><span class="o">*</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">ph</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">v</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">ph</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">+=</span> <span class="n">alpha</span><span class="o">*</span><span class="p">(</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">v</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">c</span> <span class="o">+=</span> <span class="n">alpha</span><span class="o">*</span><span class="p">(</span><span class="n">ph</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">ph</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
                <span class="n">mse</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="n">v</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="n">v</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">mse</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">/=</span> <span class="n">N</span>
        <span class="k">return</span> <span class="n">mse</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="example-digits">
<h3>Example: Digits<a class="headerlink" href="#example-digits" title="Permalink to this heading">#</a></h3>
<p>Lets try RBM with the <code class="docutils literal notranslate"><span class="pre">digits</span></code> dataset in <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">digits</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_digits</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">imgrid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Nh</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;x: N*Pv*Ph image array&quot;&quot;&quot;</span>
    <span class="n">N</span><span class="p">,</span> <span class="n">Pv</span><span class="p">,</span> <span class="n">Ph</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">if</span> <span class="n">Nh</span> <span class="o">==</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">Nh</span> <span class="o">=</span> <span class="p">(</span><span class="nb">int</span><span class="p">)(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">N</span><span class="p">)</span><span class="o">/</span><span class="mi">10</span><span class="p">)</span><span class="o">*</span><span class="mi">10</span><span class="p">)</span> <span class="k">if</span> <span class="n">N</span><span class="o">&gt;</span><span class="mi">10</span> <span class="k">else</span> <span class="n">N</span>
    <span class="n">Nv</span> <span class="o">=</span> <span class="p">(</span><span class="nb">int</span><span class="p">)(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="n">Nh</span><span class="p">))</span>  <span class="c1"># rows</span>
    <span class="k">if</span> <span class="n">N</span> <span class="o">&lt;</span> <span class="n">Nv</span><span class="o">*</span><span class="n">Nh</span><span class="p">:</span>   <span class="c1"># pad by zeros</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">Nv</span><span class="o">*</span><span class="n">Nh</span><span class="o">-</span><span class="n">N</span><span class="p">,</span><span class="n">Pv</span><span class="p">,</span><span class="n">Ph</span><span class="p">))))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">Nv</span><span class="p">,</span><span class="n">Nh</span><span class="p">,</span><span class="n">Pv</span><span class="p">,</span><span class="n">Ph</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">Nv</span><span class="o">*</span><span class="n">Pv</span><span class="p">,</span> <span class="n">Nh</span><span class="o">*</span><span class="n">Ph</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">extent</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">Nh</span><span class="p">,</span><span class="n">Nv</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># select only 0-3</span>
<span class="n">yt</span> <span class="o">=</span> <span class="n">digits</span><span class="o">.</span><span class="n">target</span><span class="p">[</span><span class="n">digits</span><span class="o">.</span><span class="n">target</span><span class="o">&lt;</span><span class="mi">4</span><span class="p">]</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">digits</span><span class="o">.</span><span class="n">target</span><span class="o">&lt;</span><span class="mi">4</span><span class="p">]</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># 0-1</span>
<span class="n">x</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(720, 64)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">imgrid</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/8a3506e4116b60708677c65c464fecf211373f5e1a8baa6ed4333ba2542a0fba.png" src="_images/8a3506e4116b60708677c65c464fecf211373f5e1a8baa6ed4333ba2542a0fba.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create a RBM for 8*8 images</span>
<span class="n">Mv</span> <span class="o">=</span> <span class="mi">8</span><span class="o">*</span><span class="mi">8</span>
<span class="n">Mh</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">rb</span> <span class="o">=</span> <span class="n">RBM</span><span class="p">([</span><span class="n">Mv</span><span class="p">,</span> <span class="n">Mh</span><span class="p">],</span> <span class="n">winit</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">imgrid</span><span class="p">(</span><span class="n">rb</span><span class="o">.</span><span class="n">W</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/25f16200d4a5f2256004ad1f3589970a5aeea30d7e7456883364423852489295.png" src="_images/25f16200d4a5f2256004ad1f3589970a5aeea30d7e7456883364423852489295.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">500</span>   <span class="c1"># training set size</span>
<span class="n">mse</span> <span class="o">=</span> <span class="n">rb</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">x</span><span class="p">[:</span><span class="n">N</span><span class="p">],</span> <span class="n">K</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">mse</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;t&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;mse&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/279c907404f04c8d6d8f85efbab39cb1995a49cdd11ab732e01aafb52ddaa208.png" src="_images/279c907404f04c8d6d8f85efbab39cb1995a49cdd11ab732e01aafb52ddaa208.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Learned weights</span>
<span class="n">imgrid</span><span class="p">(</span><span class="n">rb</span><span class="o">.</span><span class="n">W</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/81494f856975c156ee55350eac394aecb64da5cbeaed43ddb21ed133e30f846e.png" src="_images/81494f856975c156ee55350eac394aecb64da5cbeaed43ddb21ed133e30f846e.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Test by new data</span>
<span class="n">M</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">N</span><span class="p">:</span><span class="n">N</span><span class="o">+</span><span class="n">M</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">imgrid</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">rb</span><span class="o">.</span><span class="n">phv</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">h</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">vr</span> <span class="o">=</span> <span class="n">rb</span><span class="o">.</span><span class="n">pvh</span><span class="p">(</span><span class="n">h</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>  <span class="c1"># reconstructed</span>
<span class="n">imgrid</span><span class="p">(</span><span class="n">vr</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">)));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/6299df94b1f1d611ff4d351dff00d9b68ae7689f78c429cefffdc34355924264.png" src="_images/6299df94b1f1d611ff4d351dff00d9b68ae7689f78c429cefffdc34355924264.png" />
</div>
</div>
</section>
</section>
<section id="variational-autoencoders-vae">
<h2>7.5 Variational Autoencoders (VAE)<a class="headerlink" href="#variational-autoencoders-vae" title="Permalink to this heading">#</a></h2>
<p>The objective of learning in a generative model is to minimize the discrepancy between the observed data distribution <span class="math notranslate nohighlight">\(p(\x)\)</span> and the generated data distribution</p>
<div class="math notranslate nohighlight">
\[
    \int_\z p_{\theta}(\x|\z) p(\z) d\z
\]</div>
<p>while assuming a simple low-dimensional prior distribution <span class="math notranslate nohighlight">\(p(\z)\)</span> of the latent varible, such as independent Gaussians.</p>
<p>A standard way to do this is to maximize the log likelihood for data <span class="math notranslate nohighlight">\((\x_1,...,\x_N)\)</span>:</p>
<div class="math notranslate nohighlight">
\[
    \sum_{n=1}^N\log p_{\theta}(\x_n) = \sum_n\log\int_\z p_\theta(\x_n|\z) p(\z) d\z 
\]</div>
<p>A problem with this approach is that computing <span class="math notranslate nohighlight">\(p_{\theta}(x)\)</span> is often intractable: it is hard to compute the integration over all possible ranges of <span class="math notranslate nohighlight">\(\z\)</span> with a high dimension.</p>
<p>In the <em>autoencoder</em> framework, we consider two networks:</p>
<ul class="simple">
<li><p>The <em>encoder</em> network that maps the data <span class="math notranslate nohighlight">\(\x\)</span> to the latent variable<span class="math notranslate nohighlight">\(\z\)</span>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
    q_\phi(\z|\x)
\]</div>
<ul class="simple">
<li><p>The <em>decoder</em> network to regenerate the data <span class="math notranslate nohighlight">\(\z\)</span> from the latent variable <span class="math notranslate nohighlight">\(\z\)</span>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
    p_\theta(\x|\z).
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">draw_net</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">,</span><span class="sa">r</span><span class="s2">&quot;$q_\phi(z|x)$&quot;</span><span class="p">,</span><span class="s2">&quot;z&quot;</span><span class="p">,</span><span class="sa">r</span><span class="s2">&quot;$p_\theta(x|z)$&quot;</span><span class="p">,</span><span class="s2">&quot;x&quot;</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/fea3cdaf999e4c26386987db2dd9c201040419863b15dcbf59abdf2761210aa5.png" src="_images/fea3cdaf999e4c26386987db2dd9c201040419863b15dcbf59abdf2761210aa5.png" />
</div>
</div>
<p>The goal of learning of autoencoder is to reduce the reconstruction error, or to maximize the likelihood of regenerated data</p>
<div class="math notranslate nohighlight">
\[
    \sum_{n=1}^N\log p_\theta(\x_n) = 
    \sum_{n=1}^N\log\int_\z p_\theta(\x_n|\z) q_\phi(\z|\x_n) d\z 
\]</div>
<p>while keeping the data-constrained latent variable distribution <span class="math notranslate nohighlight">\(q_\phi(\z|\x_n)\)</span> close to a desired prior distribution <span class="math notranslate nohighlight">\(p(\z)\)</span>, such as normal gaussian.</p>
<p>This can be achieved by maximizing the *expected variational lower bound (ELBO):</p>
<div class="math notranslate nohighlight">
\[
    \mathcal{L} := 
    \sum_{n=1}^N\log\int_\z p_\theta(\x_n|\z) q_\phi(\z|\x_n) d\z
    - \mbox{KL}[q_\phi(\z|\x_n) || p(\z)]
\]</div>
<section id="reparametrization-trick">
<h3>Reparametrization trick<a class="headerlink" href="#reparametrization-trick" title="Permalink to this heading">#</a></h3>
<p>For optimizing the parameters <span class="math notranslate nohighlight">\(\phi\)</span> and <span class="math notranslate nohighlight">\(\theta\)</span> during training the generative model, we want to apply the gradient descent algorithm. We consider a model consisting of two neural networks; one encoder and one decoder network. Since our latent representation <span class="math notranslate nohighlight">\(z\)</span> is a stochastic variable, it is mathematically not possible to backpropagate the error through the stochastic network nodes. Therefore, we need to apply a reparametrization trick (Kingma and Welling 2014).</p>
<p>Instead of encoding the stochastic variable z, it will generate its mean and standard deviation plus adding some Gaussian noise (see Figure 4). In that case, <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> are deterministic, so that we can use backpropagation to update our network parameters during training.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">draw_net</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="sa">r</span><span class="s2">&quot;$f_\phi(x)_i$&quot;</span><span class="p">,</span><span class="sa">r</span><span class="s2">&quot;$z_i$&quot;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$\mu_i$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$\sigma_i$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$\epsilon\sim N(0,1)$&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/0dca0bc3d5255036e1a80e1cd778de356be3bc27983d5223685897c8d49c945d.png" src="_images/0dca0bc3d5255036e1a80e1cd778de356be3bc27983d5223685897c8d49c945d.png" />
</div>
</div>
</section>
</section>
<section id="deep-learning-tools-and-pre-trained-weights">
<h2>7.6 Deep learning tools and pre-trained weights<a class="headerlink" href="#deep-learning-tools-and-pre-trained-weights" title="Permalink to this heading">#</a></h2>
<p>An important factor in todays boom in deep learning is the availability of open-source software tools that are optimized for general-purpose graphics processing units (GPUs). <em>Tensorflow</em> and <em>Pytorch</em> are examples of most popular tools today.</p>
<p>In addition, some of the network weights that were trained by large data sets and achieved high performance in competitions are publicly available. Training of deep neural networks require heavy computing, but running a deep neural network for classification or prediction is much less demanding.
By downloading such pre-trained weights, anybody can reproduce state-of-the-art performance in deep neural networks. You can further customize or improve the model by adding your own higher layers on top of those pre-trained networks.</p>
</section>
<section id="visual-cortex-and-covolutional-networks">
<h2>7.7 Visual cortex and covolutional networks<a class="headerlink" href="#visual-cortex-and-covolutional-networks" title="Permalink to this heading">#</a></h2>
<section id="simple-and-complex-receptive-fields">
<h3>Simple and complex receptive fields<a class="headerlink" href="#simple-and-complex-receptive-fields" title="Permalink to this heading">#</a></h3>
<p>Soon after the discovery of orientation selective tuning of cat visual cortex neurons, Hubel &amp; Wiesel further found that there are neurons that show <em>complex</em> receptive fields. Those neurons respond to presentation of bars in particular orientations in different positions in their large receptive fields.</p>
<p>They suggested a networks architecutre that simple cells sum together inputs from on- or off-center cells in the thalamus, while complex cells sum together inputs from simple cells with similar orientation selectivity.</p>
</section>
<section id="neocognitron">
<h3>Neocognitron<a class="headerlink" href="#neocognitron" title="Permalink to this heading">#</a></h3>
<p>Inspired by the simple and complex receptive fields found by Hubel &amp; Wiesel, Fukushima proposed a pattern classification neural network model called <em>Cognitron</em> and then its extended version <em>Neocognitron</em> (Fukushima 1980).</p>
</section>
<section id="analyzing-neural-coding-by-trained-deep-networks">
<h3>Analyzing neural coding by trained deep networks<a class="headerlink" href="#analyzing-neural-coding-by-trained-deep-networks" title="Permalink to this heading">#</a></h3>
<p>Inspired by the success of deep neural networks in visual object recognition, Yamins and colleagues explored how such trained deep neural networks can be used to characterize the response properties of higher visual cortex neurons, which are not easy to express by mathematical formulas.</p>
<p>They first trained a deep neural network to perform visual object recognition task and then used the responses of the higher layers of the deep neural network to predict the activity of visual cortex neurons when the same stimulus was presented.</p>
<p>They found that the response propereties of the highest visual cortical area, inferior temporal (IT) cortex, was well predicted using the activities of the highest layer of the trained deep network, while those in the middle level of the visual cortex, area V4, were better predicted by the responses of the intermediate layers of the deep network (Yamins et al. 2014, 2016)</p>
<img src="https://www.pnas.org/cms/10.1073/pnas.1403112111/asset/7a11a5c7-9ea1-44fc-8e46-b050d1abda83/assets/graphic/pnas.1403112111fig02.jpeg" width="500px">
Figure 7.3: Prediction of visual cortical neural activities by trained deep neural networks (Yamins et al. 2014).</section>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Bishop CM (2006) Pattern Recognition and Machine Learning. Springer.
<a class="reference external" href="https://www.microsoft.com/en-us/research/people/cmbishop/prml-book/">https://www.microsoft.com/en-us/research/people/cmbishop/prml-book/</a></p>
<ul>
<li><p>Chapter 5: Neural networks</p></li>
</ul>
</li>
<li><p>Goodfellow I, Bengio Y, Courville A (2016) Deep Learning. MIT Press. (<a class="reference external" href="http://www.deeplearningbook.org">http://www.deeplearningbook.org</a>)</p>
<ul>
<li><p>3.13 Information Theory</p></li>
<li><p>19.4 Variational Inference and Learning</p></li>
<li><p>Chapter 20 Deep Generative Models</p></li>
</ul>
</li>
<li><p>Backpropagation</p>
<ul>
<li><p>Rumelhart DE, Hinton GE, Williams RJ (1986). Learning Representations by Back-Propagating Errors. Nature, 323, 533-536. <a class="reference external" href="https://doi.org/10.1038/323533a0">https://doi.org/10.1038/323533a0</a></p></li>
</ul>
</li>
<li><p>Boltzmann machines</p>
<ul>
<li><p>Ackley DH, Hinton GE, Sejnowski TJ (2010). A Learning Algorithm for Boltzmann Machines*. Cogn Sci, 9, 147-169. <a class="reference external" href="https://doi.org/10.1207/s15516709cog0901_7">https://doi.org/10.1207/s15516709cog0901_7</a></p></li>
<li><p>Salakhutdinov R, Hinton G (2012) An efficient learning procedure for deep Boltzmann machines. Neural Computation 24:1967-2006. <a class="reference external" href="https://doi.org/10.1162/NECO_a_00311">https://doi.org/10.1162/NECO_a_00311</a></p></li>
</ul>
</li>
<li><p>Variational autoencoders</p>
<ul>
<li><p>Kingma DP, Welling M (2014). Auto-encoding variational Bayes. International Conference on Learning Representations (ICLR). <a class="reference external" href="https://doi.org/10.48550/arXiv.1312.6114">https://doi.org/10.48550/arXiv.1312.6114</a></p></li>
<li><p>Doersch, C. (2016). Tutorial on variational autoencoders. arXiv:1606.05908. <a class="reference external" href="https://doi.org/10.48550/arXiv.1606.05908">https://doi.org/10.48550/arXiv.1606.05908</a></p></li>
</ul>
</li>
<li><p>Visual cortex and convolutional neural networks</p>
<ul>
<li><p>Hubel DH, Wiesel TN (1962). Receptive fields, binocular interaction and functional architecture in the cats visual cortex. Journal of Physiology, 160, 106-154. <a class="reference external" href="https://doi.org/10.1113/jphysiol.1962.sp006837">https://doi.org/10.1113/jphysiol.1962.sp006837</a></p></li>
<li><p>Fukushima K (1980). Neocognitron: a self organizing neural network model for a mechanism of pattern recognition unaffected by shift in position. Biol Cybern, 36, 193-202. <a class="reference external" href="https://doi.org/10.1007/BF00344251">https://doi.org/10.1007/BF00344251</a></p></li>
<li><p>Yamins DL, Hong H, Cadieu CF, Solomon EA, Seibert D, DiCarlo JJ (2014). Performance-optimized hierarchical models predict neural responses in higher visual cortex. Proceedings of the National Academy of Sciences USA, 111, 8619-24. <a class="reference external" href="https://doi.org/10.1073/pnas.1403112111">https://doi.org/10.1073/pnas.1403112111</a></p></li>
<li><p>Horikawa T, Kamitani Y (2017). Generic decoding of seen and imagined objects using hierarchical visual features. Nature Communications, 8. <a class="reference external" href="https://doi.org/10.1038/ncomms15037">https://doi.org/10.1038/ncomms15037</a></p></li>
</ul>
</li>
</ul>
</section>
<div class="toctree-wrapper compound">
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="Bayesian_Exercise.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Bayesian Approaches: Exercise</p>
      </div>
    </a>
    <a class="right-next"
       href="Deep_Exercise.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Chapter 7: Deep Learning: Exercise</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#contents">Contents</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-layer-neural-networks">7.1 Multi-Layer Neural Networks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#universality-of-multi-layer-neural-networks">Universality of multi-layer neural networks</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#recurrent-neural-networks">Recurrent neural networks</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#back-propagation-learning">7.2 Back-Propagation Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-sine-wave">Example: Sine wave</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-nn-for-classification">Deep NN for classification</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-exclusive-or">Example: Exclusive OR</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-donut">Example: Donut</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-class-classification">Multi-class classification</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-generative-models">7.3 Deep Generative Models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#boltzmann-machine">Boltzmann machine</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-generative-networks">Deep generative networks</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#restricted-boltzmann-machines">7.4 Restricted Boltzmann Machines</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-by-contrastive-divergence-cd">Learning by contrastive divergence (CD)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-digits">Example: Digits</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variational-autoencoders-vae">7.5 Variational Autoencoders (VAE)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reparametrization-trick">Reparametrization trick</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-learning-tools-and-pre-trained-weights">7.6 Deep learning tools and pre-trained weights</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visual-cortex-and-covolutional-networks">7.7 Visual cortex and covolutional networks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-and-complex-receptive-fields">Simple and complex receptive fields</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#neocognitron">Neocognitron</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#analyzing-neural-coding-by-trained-deep-networks">Analyzing neural coding by trained deep networks</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Kenji Doya
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
       Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>