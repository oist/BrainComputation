{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatper 6. Bayesian Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ % Latex macros\n",
    "\\newcommand{\\mat}[1]{\\begin{pmatrix} #1 \\end{pmatrix}}\n",
    "\\newcommand{\\p}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\renewcommand{\\b}[1]{\\boldsymbol{#1}}\n",
    "\\newcommand{\\c}[1]{\\mathcal{#1}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents    \n",
    "* Bayes' theorem  \n",
    "* Bayesian linear regression (Bishop, Chater 3)  \n",
    "* Bayesian model comparison  \n",
    "* Bayesian networks  (Bishop, Chater 8)  \n",
    "* Dynamic Bayesian inference\n",
    "* Bayesian Brain  \n",
    "    * Sensory psychophysics  \n",
    "    * Cortical circuit  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes’ Theorem\n",
    "\n",
    "From the product rule of the joint probability\n",
    "\n",
    "$$  p(X,Y) = p(Y|X) p(X) $$\n",
    "\n",
    "and the symmetry of joint probability \n",
    "\n",
    "$$ p(X,Y)=p(Y,X),$$\n",
    "\n",
    "we have the relationship \n",
    "\n",
    "$$ p(X|Y)p(Y) = p(Y|X)p(X),$$\n",
    "\n",
    "which brings us to Bayes' theorem:  \n",
    "\n",
    "$$  p(X|Y) = \\frac{p(Y|X)p(X)}{p(Y)}. $$\n",
    "\n",
    "Bayes' theorem relates a conditional probability $p(X|Y)$ to the one in the opposite direction $p(Y|X)$.\n",
    "This simple formula, however, has turned out to be very insightful in the context of sensory processing and learning. \n",
    "\n",
    "Suppose $X$ is an invisible state of your interest, such as a prey or predator hiding in a bush, and $Y$ is a noisey sensory observation.\n",
    "\n",
    "* Your knowledge or assumption about the state probability of different states is represented by $p(X)$, called *prior probability*.  \n",
    "\n",
    "* What sensory input $Y=y$ is observed if the state is $X=x$ is represented by a sensory observation model $p(Y|X)$.  \n",
    "\n",
    "* For a given sensory observation $y$, the probability for such an observation with the state $x$ $p(Y=y|X=x)$ is as the *likelihood* of the state $x$. As a function of differnt states $X$, $p(Y=y|X)$ is called the *likelihood function*.\n",
    "\n",
    "* The probability of the state $X$ after observing $y$, $p(X|Y=y)$ is called the *posterior probability*.\n",
    "\n",
    "Bayes' theorem in this case\n",
    "\n",
    "$$  p(X|Y=y) = \\frac{p(Y=y|X)p(X)}{p(Y=y)} $$\n",
    "\n",
    "$$  \\propto p(Y=y|X)p(X) $$\n",
    "\n",
    "gives a theoretical basis of how to combine the prior knowledge $p(X)$ and sensory evidence $y$.  \n",
    "It is intuitive that the posterior probability $p(X|Y=y)$ is proportional to the product of the prior prbability $p(X)$ and the likelihood $p(Y=y|X)$ for oberving $y$.\n",
    "\n",
    "The denominator $p(Y=y)$ is called the *marginal likelhood* and serves as the normalizing factor so that the posterior probability sums or intergrates to one.\n",
    "\n",
    "The marginal likelhood $p(Y=y)$ is the probability of observing $y$ by considering all the possible states $X$, and generally computed by marginalizing the joint probability\n",
    "\n",
    "$$  p(Y=y) = \\sum_X p(Y=y|X=x)p(X=x) $$\n",
    "\n",
    "or\n",
    "\n",
    "$$ p(Y=y) = \\int_X p(Y=y|X=x)p(X=x) dx. $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: mouse in a bush\n",
    "\n",
    "You are a cat chasing a mouse and saw it ran behind three bushes.\n",
    "\n",
    "You know about half of the case a hiding mouse makes a sound, but about 10% of the time you hear sound just by the wind.\n",
    "That gives you a sensory observation model:\n",
    "| $p(Y \\vert X)$ | no mouse $X=0$ | mouse hiding $X=1$ |\n",
    "| --- | :---: | :---: |\n",
    "| no sound $Y=0$  | 0.9 | 0.5 |\n",
    "| sound $Y=1$  | 0.1 | 0.5 |\n",
    "\n",
    "Then you heard a rustuling sound from one bush. \n",
    "Then what is the probability of a mouse hiding behind the bush, $p(X=1|Y=1)$?\n",
    "From the above table, 0.5?\n",
    "\n",
    "No, actually. In the 'heard' row, 0.1 and 0.5 do not sum up to one. They are likelihoods $p(Y=1|X)$, but not probability distribution $p(X|Y=1)$ for the mouse to be in the bush or not.\n",
    "\n",
    "The mouse should be one of the three bushes, so you would assume that the prior probability of the mouse in this bush is 1/3:\n",
    "\n",
    "| prior probability | no mouse $X=0$ | mouse hiding $X=1$ |\n",
    "| :---: | :---: | :---: |\n",
    "| $p(X)$ | 2/3 | 1/3 |\n",
    "\n",
    "By having this prior probability, we can use Bayes' theorem:\n",
    "\n",
    "$$  p(X=1|Y=1) = \\frac{p(Y=1|X=1)p(X=1)}{p(Y=1|X=0)p(X=0)+p(Y=1|X=1)p(X=1)}  $$\n",
    "\n",
    "$$  = \\frac{0.5*1/3}{0.1*2/3+0.5*1/3}\n",
    "    = \\frac{5}{7} \\simeq 0.71  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Bayesian Inference\n",
    "\n",
    "A useful property of Bayesian inference is that you can apply it iteratively to incoming data stream.\n",
    "\n",
    "We denote the sequence of observations up to time $t$ as\n",
    "\n",
    "$$  y_{1:t}=(y_1,...,y_t)  $$\n",
    "\n",
    "and want to estimate the cause $x$ of these observations\n",
    "\n",
    "$$  p(x|y_{1:t}) = \\frac{p(y_{1:t}|x)\\ p(x)}{p(y_{1:t})}  $$\n",
    "\n",
    "If the observations are independent, their joint distribution is a product\n",
    "\n",
    "$$  p(y_{1:t}|x) = p(y_1|x)\\cdots p(y_t|x)  $$\n",
    "and thus the posterior can be decomposed as\n",
    "\n",
    "$$  p(x|y_{1:t}) = \\frac{p(y_1|x)\\cdots p(y_{t-1}|x)\\ p(y_t|x)\\ p(x)}{p(y_1)\\cdots p(y_{t-1})\\ p(y_t)}  $$\n",
    "\n",
    "$$  = \\frac{p(y_t|x)}{p(y_t)}\\ \\frac{p(y_1|x)\\cdots p(y_{t-1}|x)\\ p(x)}{p(y_1)\\cdots p(y_{t-1}) }  $$\n",
    "\n",
    "$$  = \\frac{p(y_t|x)\\ p(x|y_{1:t-1})}{p(y_t)}.  $$\n",
    "\n",
    "This means that the posterior $p(x|y_{1:t-1})$ that you computed by time $t-1$ serves as the prior to be combined with the likelihood for the new coming data $p(y_t|x)$ for computing the new posterior $p(x|y_{1:t})$.\n",
    "\n",
    "This iterative update of the posterior is practically helpful in online inference utilizing whatever data available so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coin toss\n",
    "\n",
    "Here is a simple example of estimating the parameter $\\mu$, probability for a coin to land head up, during multiple tosses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take samples\n",
    "mu = 0.4  # probability of head\n",
    "N = 10   # number of samples\n",
    "y = np.random.choice(2, N, p=[1-mu, mu]) # binary observation sequence\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = 0.01  # plot step\n",
    "x = np.arange( 0, 1, dx)  # range of the parameter\n",
    "prior = np.ones( len(x))  # Assume a uniform prior\n",
    "plt.figure(figsize=(6,10))\n",
    "for t in range(N):\n",
    "    plt.subplot(N//2, 2, t+1)  # a new figure\n",
    "    # prior\n",
    "    plt.plot( x, prior, 'b')\n",
    "    # observation\n",
    "    plt.plot( y[0:t+1], np.arange(t+1)/N, 'ko')\n",
    "    # likelihood\n",
    "    likelihood = x*y[t] + (1-x)*(1-y[t]) # theta if head, 1-theta if tail\n",
    "    plt.plot( x, likelihood, 'g')\n",
    "    # product\n",
    "    prilik = prior*likelihood\n",
    "    plt.plot( x, prilik,'c')\n",
    "    # posterior by normalization\n",
    "    marginal = sum(prilik)*dx    # integrate over the parameter range\n",
    "    posterior = prilik/marginal  # normalize\n",
    "    plt.plot( x, posterior, 'r')\n",
    "    plt.xlabel(r'$\\mu$')\n",
    "    if t==0:\n",
    "        plt.legend(('prior', 'observation', 'likelihood', 'prior*like.', 'posterior'))\n",
    "    plt.title(f't = {t+1}')\n",
    "    # posterior as a new prior\n",
    "    prior = posterior\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "As more data are collected, the posterior distribution of $\\mu$ becomes sharper and colser to the true value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For binary observations $y_{1:n}=(y_1,...,y_n)$, under uniform prior probability, the posterior probability of the mean $mu$ is\n",
    "\n",
    "$$ p(\\mu|y_{1:n}) \\propto \\mu^{n_1} (1-\\mu)^{n_0} $$\n",
    "\n",
    "where $n_1$ and $n_0$ are the number of observations of $1$ and $0$, respectively. This is an example of *beta distribution*:\n",
    "\n",
    "$$ p(x; \\alpha, \\beta) \\propto x^{\\alpha-1} (1-x)^{\\beta-1} $$\n",
    "\n",
    "with $\\alpha=n_1+1$ and $\\beta=n_0+1$. A uniform prior distribution is represented by $\\alpha = \\beta = 1$.\n",
    "\n",
    "If a prior and the posterior are represented by the same class of distribution, the prior is called the conjugate prior for the observation model. Beta distribution is the conjugate prior for the binary (Bernoulli) observation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_beta = [[1,1], [1,2], [2,2], [5,3]]\n",
    "x = np.linspace(0., 1.)\n",
    "for ab in alpha_beta:\n",
    "    p = scipy.stats.beta.pdf(x, ab[0], ab[1])\n",
    "    plt.plot(x, p)\n",
    "plt.xlabel('x'); plt.ylabel('p(x)')\n",
    "plt.title(r'beta distribution $[\\alpha,\\beta]$')\n",
    "plt.legend(alpha_beta);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian observations\n",
    "\n",
    "Estimate the mean $\\mu$ and the standard deviationn $\\sigma$ from noisy observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noisy observation: y = N(mu,sigma)\n",
    "mu = 1\n",
    "sigma = 2\n",
    "N = 10\n",
    "y = mu + sigma*np.random.randn(N)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start from a uniform prior\n",
    "rmu = 5; dmu = 0.2   # range and step of mu\n",
    "rsig = 5;  dsig = 0.2 # range and step of sigma\n",
    "m = np.arange(-rmu, rmu, dmu)\n",
    "s = np.arange(rsig, 0, -dsig)\n",
    "M, S = np.meshgrid(m, s)  # grid of mu and sigma\n",
    "prior = np.ones_like(M)/(2*rmu*rsig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(N):\n",
    "    plt.figure()\n",
    "    plt.subplot(1, 2, 1)\n",
    "    # observation\n",
    "    plt.plot( y[0:n+1], dsig+rsig*np.arange(n+1)/N, 'w+')\n",
    "    # likelihood\n",
    "    likelihood = np.exp(-((y[n]-M)/S)**2/2)/(np.sqrt(2*np.pi)*S)\n",
    "    plt.imshow(likelihood, extent=(-rmu,rmu,0,rsig))\n",
    "    plt.xlabel(r'$\\mu$'); plt.ylabel(r'$\\sigma$');\n",
    "    plt.title(f'likelihood {n+1}')\n",
    "    plt.colorbar(shrink=0.25)\n",
    "    # posterior\n",
    "    plt.subplot(1, 2, 2)\n",
    "    prilik = prior*likelihood\n",
    "    #plt.imshow(prilik, extent=(-rmu,rmu,0,rsig))\n",
    "    marginal = np.sum(prilik)*dmu*dsig\n",
    "    posterior = prilik/marginal\n",
    "    plt.imshow(posterior, extent=(-rmu,rmu,0,rsig))\n",
    "    plt.xlabel(r'$\\mu$'); plt.ylabel(r'$\\sigma$');\n",
    "    plt.title(f'posterior {n+1}')\n",
    "    prior = posterior  # new prior\n",
    "    plt.colorbar(shrink=0.25)\n",
    "    # true value\n",
    "    plt.plot( [mu], [sigma], 'r*')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we consider a case where $y$ is an observation of $x$ with Gaussian noise\n",
    "\n",
    "$$ p(y|x) \\propto e^{-\\frac{(y-x)^2}{2\\sigma_1^2}} $$\n",
    "\n",
    "If we assume that the prior distribution of $x$ is also Gaussian\n",
    "\n",
    "$$ p(x) \\propto e^{-\\frac{(x-\\mu_0)^2}{2\\sigma_0^2}} $$\n",
    "\n",
    "then the posterior distribution also takes a Gaussian form:\n",
    "\n",
    "$$ p(x|y) \\propto p(x)p(y|x)\n",
    "    \\propto e^{-\\frac{(x-\\mu_0)^2}{2\\sigma_0^2}} e^{-\\frac{(y-x))^2}{2\\sigma_1(x)^2}} \n",
    "    = e^{-\\frac{(x-\\mu_0)^2}{2\\sigma_0^2} - \\frac{(x-y)^2}{2\\sigma_1^2}} \n",
    "    \\propto e^{-\\frac{(x-\\mu_2)^2}{2\\sigma_2^2}} $$\n",
    "\n",
    "By considering the coefficients of $x^2$ and $x$ of the exponent, we have\n",
    "\n",
    "$$ \\frac{1}{\\sigma_0^2}+\\frac{1}{\\sigma_1^2} = \\frac{1}{\\sigma_2^2} $$\n",
    "\n",
    "$$ \\frac{\\mu_0}{\\sigma_0^2}+\\frac{y}{\\sigma_1^2} = \\frac{\\mu_2}{\\sigma_2^2} $$\n",
    "\n",
    "From these we find the mean and the variance of the posterior as\n",
    "\n",
    "$$ \\sigma_2^2 = \\frac{1}{\\frac{1}{\\sigma_0^2}+\\frac{1}{\\sigma_1^2}}\n",
    "    = \\frac{\\sigma_0^2 \\sigma_1^2}{\\sigma_0^2+\\sigma_1^2} $$\n",
    "\n",
    "$$ \\mu_2 = \\frac{\\sigma_2^2}{\\sigma_0^2}\\mu_0+\\frac{\\sigma_2^2}{\\sigma_1^2}y \n",
    "    = \\frac{\\sigma_1^2}{\\sigma_0^2+\\sigma_1^2}\\mu_0+\\frac{\\sigma_0^2}{\\sigma_0^2+\\sigma_1^2}y $$\n",
    "\n",
    "The mean of the posterior is a weighted average of the mean of the prior and the new observation; larger the weight for smaller the variance.\n",
    "\n",
    "If there are multiple independent observations, such as by vision, audition, and haptics, they should also be weighting based on the ratio of the variances of sensory obervations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a Gaussian likelihood function, the conjugate priors for the mean $\\mu$ is also a Gaussian.\n",
    "As we saw many $\\frac{1}{\\sigma^2}$ above, it is often more convenient to parameterize a Gaussian distribution by the inverse variance, or the precision $\\lambda=\\frac{1}{\\sigma^2}$.\n",
    "For the presicision, the conjugate prior is a Gamma distribution\n",
    "\n",
    "$$ p(\\lambda) \\propto \\lambda^{\\alpha-1}e^{-\\lambda}. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.arange(6.)\n",
    "x = np.linspace(0., 8.)\n",
    "for a in alpha:\n",
    "    p = scipy.stats.gamma.pdf(x, a)\n",
    "    plt.plot(x, p)\n",
    "plt.xlabel('x'); plt.ylabel('p(x)')\n",
    "plt.title(r'gamma distribution $(\\alpha)$')\n",
    "plt.legend(alpha);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian approaches in machine learning\n",
    "\n",
    "\"Bayesian\" is quite popular in machine learning, but it is used for different meanings:\n",
    "\n",
    "* To combine prior knowledge and the likelihood from observation\n",
    "\n",
    "* To assume a graphical model of data generation for estimation of the causes\n",
    "\n",
    "* To estimate the distribution of a variable, not a single point\n",
    "\n",
    "In supervised learning:\n",
    "* avoid over fitting by introducing a prior distribution on the parameters\n",
    "* compare models by their probability of producing observed data\n",
    "\n",
    "In reinforcement learning:\n",
    "* infer the environmental state from incomplete observation\n",
    "* estimate the distribution of reward, not just the expectation\n",
    "\n",
    "In unsupervised learning:\n",
    "* infer hidden variables behind data\n",
    "    * e.g. responsibility in Mixtures of Gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Linear Regression\n",
    "\n",
    "The standard linear regression (Chapter 3) assumes a linear regression function with additive noise \n",
    "$$ t_n = \\b{w}^T\\b{x}_n + \\epsilon $$\n",
    "where $p(\\epsilon)=\\mathcal{N}(0,\\beta^{-1})$.\n",
    "\n",
    "In Bayesian linear regression, we assume that the weights are sampled from a prior distribution $p(\\b{w})=\\mathcal{N}(\\b{0},\\alpha^{-1}I)$.\n",
    "\n",
    "The likelihood of the parameter $\\b{w}$ for the target output $\\b{t}$ is\n",
    "\n",
    "$$ p(\\b{t}|X, \\b{w}, \\beta) = \\prod_{n=1}^N \\mathcal{N}(t_n|\\b{w}^T\\b{x}_n,\\beta^{-1}) $$\n",
    "\n",
    "When both the prior and likelihood are Gaussian, the posterior will also be Gaussian and have the form:\n",
    "\n",
    "$$ p(\\b{w}|\\b{t}) = \\mathcal{N}(\\b{w}|\\b{m},S) $$\n",
    "\n",
    "where the mean of the posterior weights is given as\n",
    "\n",
    "$$ \\b{m} = \\beta S X^T \\bf{t} $$\n",
    "\n",
    "and the variance as\n",
    "\n",
    "$$ S = (\\alpha I + \\beta X^T X)^{-1} $$\n",
    "\n",
    "If we let $\\alpha=0$, i.e. infinitely large variance for the weight prior, this is equivalent to regular linear regression. \n",
    "\n",
    "The log posterior probability of weights is given by\n",
    "\n",
    "$$ \\log p(\\b{w}|\\b{t}) = - \\frac{\\beta}{2}\\sum_{n=1}^N \\{t_n - \\b{w}^T \\b{x}_n\\}^2\n",
    "- \\frac{\\alpha}{2} \\b{w}^T\\b{w} +\\mbox{const.}$$\n",
    "\n",
    "This presents a link with a common method of adding a penalty term for the size of the weights, or equivallently adding diagonal component in the data correlation matrix, know as *ridge regression*, which minimizes\n",
    "\n",
    "$$ E(\\b{w}) = \\frac{1}{2}\\sum_{n=1}^N \\{t_n - \\b{w}^T \\b{x}_n\\}^2\n",
    "+ \\frac{\\lambda}{2} \\b{w}^T\\b{w} $$\n",
    "\n",
    "The Bayesian regression gives a probabilistic interpretation of the regularization parameter as $\\lambda=\\frac{\\alpha}{\\beta}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use this frequently\n",
    "def gauss(x, mu=0, sigma=1):\n",
    "    \"\"\"Gaussian distribution\"\"\"\n",
    "    return np.exp(-((x-mu)/sigma)**2/2)/(np.sqrt(2*np.pi)*sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Distributions in the parameter and data spaces\n",
    "alpha = 1.  # inverse variance of weight prior\n",
    "beta = 10  # inverse variance of observation noise\n",
    "wt = np.array([-1, 1])  # 'true' weights\n",
    "# sample data\n",
    "N = 6\n",
    "xrange = [-1, 1]\n",
    "X = np.random.uniform(xrange[0], xrange[1], size=N)\n",
    "X = np.c_[np.ones(N), X]  # prepend 1 in the leftmost column\n",
    "t = wt@X.T + np.random.normal(size=N)/np.sqrt(beta)  # targets with noise\n",
    "# for weight space visualization\n",
    "W = np.linspace(-3, 3, 30)\n",
    "W0, W1 = np.meshgrid(W, W)\n",
    "K = 10  # weight samples\n",
    "pw = gauss(W0)*gauss(W1)\n",
    "for n in range(N):\n",
    "    plt.figure()\n",
    "    # likelihood\n",
    "    like = gauss(t[n] - (W0+W1*X[n,1]), sigma=beta**(-0.5))\n",
    "    plt.subplot(1,3,1)   # left\n",
    "    plt.pcolormesh(W, W, like)\n",
    "    plt.axis('square')\n",
    "    plt.title(\"Likelihood\"); plt.xlabel(\"w0\"); plt.ylabel(\"w1\");\n",
    "    # new posterior\n",
    "    S = np.linalg.inv(alpha*np.eye(2) + beta*X[:n+1].T@X[:n+1])\n",
    "    m = beta*S@X[:n+1].T@t[:n+1]\n",
    "    # print(n, ': m =', m, '; S =', S)\n",
    "    plt.subplot(1,3,2)\n",
    "    post = pw*like\n",
    "    plt.pcolormesh(W, W, post)\n",
    "    plt.axis('square')\n",
    "    plt.title(\"Posterior\"); plt.xlabel(\"w0\"); plt.ylabel(\"w1\");\n",
    "    # sample weights\n",
    "    wpost = np.random.multivariate_normal(m, S, K)\n",
    "    plt.plot(wpost[:,0], wpost[:,1], \"w+\")\n",
    "    # plot model samples\n",
    "    xrange = np.array([-1., 1.])   # range of input x\n",
    "    plt.subplot(1,3,3)\n",
    "    for k in range(K):\n",
    "        plt.plot(xrange, wpost[k,0]+wpost[k,1]*xrange, lw=0.5)\n",
    "    # true line\n",
    "    plt.plot(xrange, wt[0]+wt[1]*xrange, \"k\")\n",
    "    plt.plot(X[:n+1,1], t[:n+1], \"k+\")  # training data\n",
    "    plt.gca().set_box_aspect(1)\n",
    "    plt.title(\"Model samples\"); plt.xlabel(\"x\"); plt.ylabel(\"y\");\n",
    "    plt.tight_layout()  # adjust subplot margins\n",
    "    pw = post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive distribution\n",
    "In Bayesian regression, the result is not one weight vector, but a distribution in the weight space. Then it is reasonable to consider the distribution of the output considering such uncertainty in the weigts.\n",
    "\n",
    "The output $y$ for a new input $\\b{x}$ should have the distribution\n",
    "\n",
    "$$ p(y|\\b{x},\\b{t},\\alpha,\\beta) \n",
    " = \\int p(y|\\b{x},\\b{w},\\beta)  p(\\b{w}|\\b{t},\\alpha,\\beta) d\\b{w} $$\n",
    "\n",
    "$$ = \\mathcal{N}(t|\\b{m}^T \\b{x}, \\sigma^2(\\b{x})) $$\n",
    "where the variance of the output is given by\n",
    "\n",
    "$$ \\sigma^2(\\b{x}) = \\beta^{-1} + \\b{x}^T S \\b{x} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see the example of approximating a sine function by Gaussian basis functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D Gaussian basis functions \n",
    "def gbf1(x, xrange=[-1.,1.], M=10):\n",
    "    \"\"\"Gaussian basis functions: x can be a 1D array\"\"\"\n",
    "    xc = np.linspace(xrange[0], xrange[1], num=M)  # centers\n",
    "    xd = (xc[1]-xc[0])  # interval\n",
    "    # x can be an array for N data points\n",
    "    return np.exp(-((np.tile(x,[M,1]).T - xc)/xd)**2)\n",
    "# example\n",
    "x = np.linspace(-1, 1, 100)\n",
    "plt.plot(x, gbf1(x, M=10));\n",
    "plt.xlabel(\"x\"); plt.ylabel(\"phi\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blr(X, t, alpha=1., beta=10.):\n",
    "    \"\"\"Bayesian linear regression\n",
    "    alpha: inv. variance of weight prior \n",
    "    beta: inv. variance of observation noise\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    S = np.linalg.inv(alpha*np.eye(D) + beta*X.T@X) # posterior covariance\n",
    "    m = beta*S@X.T@t   # posterior mean\n",
    "    return m, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target(x):\n",
    "    \"\"\"Target function\"\"\"\n",
    "    return np.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "N = 10\n",
    "eps = 0.2  # noise size\n",
    "xr = 4   # range of x\n",
    "x = np.random.uniform(-xr, xr, size=N)  \n",
    "f = target(x)  # target function\n",
    "t = f + np.random.normal(scale=eps, size=N) # with noise\n",
    "# data for testing/plotting\n",
    "Np = 100\n",
    "xp = np.linspace(-xr, xr, Np)\n",
    "fp = target(xp)\n",
    "plt.plot(xp, fp, \"g\")  # target function\n",
    "plt.plot(x, t, \"ro\");  # training data\n",
    "plt.xlabel(\"x\"); plt.ylabel(\"y\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 10  # number of basis functions\n",
    "Phi = gbf1(x, [-xr,xr], M)  # Gaussian basis functions\n",
    "m, S = blr(Phi, t, alpha=1., beta=10)  # Bayesian linear regression\n",
    "print(m)\n",
    "# test data\n",
    "Phip = gbf1(xp, [-xr,xr], M)\n",
    "yp = Phip@m.T\n",
    "plt.plot(xp, fp, \"g\")  # target function\n",
    "plt.plot(x, t, \"ro\");  # training data\n",
    "plt.plot(xp, yp, \"b\");  # MAP estimate\n",
    "# predictive distribution\n",
    "sigma = np.sqrt(1/beta + np.sum(Phip@S*Phip, axis=1))\n",
    "plt.plot(xp, yp+sigma, \"c\")\n",
    "plt.plot(xp, yp-sigma, \"c\")\n",
    "plt.xlabel(\"x\"); plt.ylabel(\"y\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how $N$, $M$, $\\alpha$ and $\\beta$ affect the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian model comparison\n",
    "\n",
    "We have so far considered Bayesian inference of the parameter $\\b{w}$ for a given model $\\c{M}$, such as a regression model with some input variables, but we can also think of Bayesian inference of probability over models $\\c{M}_i$, such as regression models with different choices of input variables, given data $\\c{D}$\n",
    "\n",
    "$$ p(\\c{M}_i|\\c{D}) \\propto p(\\c{M}_i) p(\\c{D}|\\c{M}_i). $$\n",
    "\n",
    "Here $p(\\c{D}|\\c{M}_i)$, the likelihood of a model given data, is called the *evidence* of the model. \n",
    "\n",
    "If we include a model explicitly in our Bayesian parameter estimation, we have\n",
    "\n",
    "$$ p(\\b{w}|\\c{D},\\c{M}_i) = \\frac{p(\\c{D}|\\b{w},\\c{M}_i)p(\\b{w}|\\c{M}_i)}{p(\\c{D}|\\c{M}_i)}, $$\n",
    "\n",
    "where we have the *evidence* as the normalizing denominator\n",
    "\n",
    "$$ p(\\c{D}|\\c{M}_i) = \\int p(\\c{D}|\\b{w},\\c{M}_i)p(\\b{w}|\\c{M}_i) d\\b{w}. $$\n",
    "\n",
    "This is also called *marginal likelihood* because it is the likelihood of the model with its parameters marginalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing model evidence\n",
    "\n",
    "In Bayesian linear regression, the model evidence with the *hyperparamters* $\\alpha$ (weight prior) and $\\beta$ (observation noise) is given by integration over all the range of the weight parameters $\\b{w}$:\n",
    "\n",
    "$$ p(\\b{t}|\\alpha,\\beta) = \\int p(\\b{t}|\\b{w},\\beta)p(\\b{w}|\\alpha) d\\b{w}, $$\n",
    "\n",
    "The log evidence is given as (Bishop, Chapter 3.5)\n",
    "\n",
    "$$ \\log p(\\b{t}|\\alpha,\\beta) \n",
    "    = -\\frac{\\beta}{2} ||\\b{t}-X\\b{m}||^2 - \\frac{\\alpha}{2} ||\\b{m}||^2 $$\n",
    "\n",
    "$$  + \\frac{1}{2}\\log|S| + \\frac{D}{2}\\log\\alpha + \\frac{N}{2}(\\log\\beta - \\log(2\\pi)) $$\n",
    "\n",
    "where $\\b{m}$ and $S$ also depend on $\\alpha$ and $\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logev(X, t, m, S, alpha, beta):\n",
    "    \"\"\"log evidence for Bayesian regression\n",
    "    m: posterior mean\n",
    "    S: posterior covariance\n",
    "    alpha: inv. variance of weight prior \n",
    "    beta: inv. variance of observation noise\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    #S = np.linalg.inv(alpha*np.eye(D) + beta*X.T@X) # posterior covariance\n",
    "    #m = beta*S@X.T@t   # posterior mean\n",
    "    em = t - X@m.T  # error with MAP estimate\n",
    "    #alpha = D/np.dot(m,m)\n",
    "    #beta = N/np.dot(em,em)\n",
    "    # log evidence\n",
    "    lev = -beta/2*np.dot(em,em) - alpha/2*np.dot(m,m) + np.log(abs(np.linalg.det(S)))/2 + D/2*np.log(alpha) + N/2*(np.log(beta/(2*np.pi)))\n",
    "    return lev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare different values of alpha\n",
    "M = 10  # number of basis functions\n",
    "alphas = np.arange(0.1, 10., 0.2)\n",
    "beta = 10.\n",
    "mse = []  # mean square errors\n",
    "lev = []  # log evidences\n",
    "for alpha in alphas:\n",
    "    Phi = gbf1(x, [-xr,xr], M)  # Gaussian basis functions\n",
    "    m, S = blr(Phi, t, alpha, beta)\n",
    "    lev.append( logev(Phi, t, m, S, alpha, beta))\n",
    "    # test data\n",
    "    Phip = gbf1(xp, [-xr,xr], M)  # Gaussian basis functions\n",
    "    err = fp - Phip@m.T  # validation error\n",
    "    mse.append( np.dot(err,err)/Np)\n",
    "    #print(alpha, beta, lev, mse)\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(alphas, mse, \"r\"); plt.ylabel(\"test error\");\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(alphas, lev, \"b\"); plt.ylabel(\"log evidence\");\n",
    "plt.xlabel(r\"$\\alpha$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare different values of beta\n",
    "M = 10  # number of basis functions\n",
    "alpha = 3. \n",
    "betas = np.arange(0.5, 50., 0.5)\n",
    "mse = []  # mean square errors\n",
    "lev = []  # log evidences\n",
    "for beta in betas:\n",
    "    Phi = gbf1(x, [-xr,xr], M)  # Gaussian basis functions\n",
    "    m, S = blr(Phi, t, alpha, beta)\n",
    "    lev.append( logev(Phi, t, m, S, alpha, beta))\n",
    "    # test data\n",
    "    Phip = gbf1(xp, [-xr,xr], M)  # Gaussian basis functions\n",
    "    err = fp - Phip@m.T  # validation error\n",
    "    mse.append( np.dot(err,err)/Np)\n",
    "    #print(alpha, beta, lev, mse)\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(betas, mse, \"r\"); plt.ylabel(\"test error\");\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(betas, lev, \"b\"); plt.ylabel(\"log evidence\");\n",
    "plt.xlabel(r\"$\\beta$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIC and AIC\n",
    "\n",
    "In addition to the parameters $\\alpha$ and $\\beta$, we want to select the number $M$ of the basis functions.\n",
    "\n",
    "The evidence for the model with $M$ parameters trained by $N$ samples are approximated by\n",
    "\n",
    "$$ \\log p(\\b{t}|M) \n",
    "    \\simeq -\\frac{\\beta}{2} ||\\b{t}-X\\b{m}||^2 - \\frac{1}{2}M\\log N $$\n",
    "\n",
    "This is know as the Bayesian information criterion (BIC). See Bishop Chapter 4.4 for details.\n",
    "\n",
    "Another popular tool for model selection is Akaike information criterion (AIC), which is given by\n",
    "\n",
    "$$ AIC = -\\frac{\\beta}{2} ||\\b{t}-X\\b{m}||^2 - M. $$\n",
    "\n",
    "AIC is based on the KL divergence of the data distributions between the true model and learned model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compare the test error and BIC for different model complexity $M$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bic(X, t, m, beta):\n",
    "    \"\"\"BIC and AIC\n",
    "    m: posterior mean\n",
    "    beta: inv. variance of observation noise\n",
    "    \"\"\"\n",
    "    N, M = X.shape\n",
    "    em = t - X@m.T  # error with MAP estimate\n",
    "    # log evidence\n",
    "    bic = -beta/2*np.dot(em,em) - M/2*np.log(N)\n",
    "    aic = -beta/2*np.dot(em,em) - M\n",
    "    return bic, aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare different values of M\n",
    "Max = 15  # max number of basis functions\n",
    "alpha = 3.\n",
    "beta = 20.\n",
    "mse = np.zeros(Max)  # mean square errors\n",
    "baic = np.zeros((Max,2))  # log evidences\n",
    "for M in range(2,Max):\n",
    "    Phi = gbf1(x, [-xr,xr], M)  # Gaussian basis functions\n",
    "    m, S = blr(Phi, t, alpha, beta)\n",
    "    baic[M] = bic(Phi, t, m, beta)\n",
    "    # test data\n",
    "    Phip = gbf1(xp, [-xr,xr], M)  # Gaussian basis functions\n",
    "    err = fp - Phip@m.T  # validation error\n",
    "    mse[M] = np.dot(err,err)/Np\n",
    "    # print(M, alpha, beta, lev[M], mse[M])\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(np.arange(2,Max), mse[2:], \"r\"); plt.ylabel(\"test error\");\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(np.arange(2,Max), baic[2:]); plt.ylabel(\"BIC, AIC\");\n",
    "plt.legend((\"BIC\",\"AIC\"))\n",
    "plt.xlabel(\"M\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen in the example of Bayesian linear regression, statistical machine learning assumes a *generative model* of the observed data and infer the posterior probability of variables of your interest, after marginalizing other unobserved variables.\n",
    "\n",
    "In doing so, representation of the relationships by graphs with random variables as nodes (or vertices) and joint or conditional probabilities as links (or edges or arcs) have turned out to be very useful. They are called *graphical models*.\n",
    "\n",
    "Directed graphs representing conditional probabilities by arrows (directed edges) are called *Bayesian networks*.\n",
    "\n",
    "For example, Bayesian linear regression can be represented as a Bayesian network as below.\n",
    "\n",
    "><img src=\"figures/BN_blr.png\" width=\"200px\">\n",
    ">Graphical model for the Bayesian linear regression.\n",
    "\n",
    "Inference in Bayesian network goes like this: as values of some variables are observed, \n",
    "* *clamp* the values of the nodes where observation was made.\n",
    "* compute the posterior distributions of the nodes along the graph by repeating Bayesian inference and marginalization\n",
    "\n",
    "In doing this, the *conditional independence* of the nodes allows efficient computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on a chain\n",
    "\n",
    "Here we consider the simplest case of a chain of discrete random variables. \n",
    "\n",
    ">![Chain](figures/BN_chain.png)\n",
    ">Graphical model of a chain of states.\n",
    "\n",
    "For each node, the variable takes an integer value $x_n \\in \\{1,...,K_n\\}$ and we consider the joint distribution over the entire nodes:\n",
    "\n",
    "$$  p(x_1,...,x_N) = p(x_1)p(x_2|x_1) \\cdots p(x_{N-1}|x_{N-2})p(x_N|x_{N-1}). $$\n",
    "\n",
    "When an observation $x_N=k$ is made at the end node, we would consider the posterior distribution\n",
    "\n",
    "$$  p(x_1,...,x_{N-1}|x_N=k) \\propto \n",
    "    p(x_1)p(x_2|x_1) \\cdots p(x_{N-1}|x_{N-2})p(x_N=k|x_{N-1}).  $$\n",
    "\n",
    "The posterior distribution of each node $x_n$ is given by marginalization\n",
    "\n",
    "$$  p(x_n|x_N=k) \\propto \\sum_{x_1}\\cdots\\sum_{x_{n-1}}\\ \n",
    "    \\sum_{x_{n+1}}\\cdots\\sum_{x_N}p(x_1,...,x_{N-1}|x_N=k) $$\n",
    "    \n",
    "$$  = \\left\\{\\sum_{x_{n-1}}p(x_n|x_{n-1}) \\cdots\n",
    "    \\sum_{x_1}p(x_2|x_1)p(x_1)\\right\\} $$\n",
    "    \n",
    "$$  \\times \\left\\{\\sum_{x_{n+1}}p(x_{n+1}|x_n) \\cdots \n",
    "    \\sum_{x_{N-1}}p(x_{N-1}|x_{N-2}) \\sum_{x_N}p(x_N=k|x_{N-1})\\right\\}  $$\n",
    "\n",
    "This can be computed efficiently by passing two *messages*:\n",
    "\n",
    "* Forward message $\\alpha_n$ of prior:\n",
    "\n",
    "$$ \\alpha_1 = p(x_1)$$\n",
    "\n",
    "$$ \\alpha_n = \\sum_{x_{n-1}} p(x_n|x_{n-1}) \\alpha_{n-1} $$\n",
    "\n",
    "* Backward message $\\beta_n$ of likelihood:\n",
    "\n",
    "$$ \\beta_N = (0,...,1,...0) $$\n",
    "with $1$ at $k$-th component and\n",
    "\n",
    "$$ \\beta_n = \\sum_{x_{n+1}} p(x_{n+1}|x_n) \\beta_{n+1} $$\n",
    "\n",
    "The posterior distribution for each node is then given by their product\n",
    "\n",
    "$$  p(x_n|x_N=k) \\propto \\alpha_n \\beta_n. $$\n",
    "\n",
    "This is called *forward-backward* algorithm. \n",
    "\n",
    "This can be generalized to tree-like networks and the algorithm using forward and backward message passing is known as *belief propagation*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov chain\n",
    "\n",
    "Here is an example of inference in a Markov chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Markov:\n",
    "    \"\"\"Class for a Markov chain\"\"\"\n",
    "    \n",
    "    def __init__(self, ptr):\n",
    "        \"\"\"Create a new environment\"\"\"\n",
    "        self.ptr = ptr  # transition matrix p(x'|x)\n",
    "        self.Ns = len(ptr)  # number of states\n",
    "        \n",
    "    def sample(self, x0=0, step=1):\n",
    "        \"\"\"generate a sample sequence from x0\"\"\"\n",
    "        seq = np.zeros(step+1, dtype=int) # sequence buffer\n",
    "        seq[0] = x0\n",
    "        for t in range(step):\n",
    "            pt1 = self.ptr[:, seq[t]] # prob. of new states\n",
    "            seq[t+1] = np.random.choice(self.Ns, p=pt1) # sample \n",
    "        return seq\n",
    "    \n",
    "    def forward(self, p0, step=1):\n",
    "        \"\"\"forward message from initial distribution p0\"\"\"\n",
    "        alpha = np.zeros((step+1, self.Ns)) # priors\n",
    "        alpha[0] = p0  # initial distribution\n",
    "        for t in range(step):\n",
    "            alpha[t+1] = self.ptr @ alpha[t] \n",
    "        return alpha\n",
    "\n",
    "    def backward(self, obs, step=1):\n",
    "        \"\"\"backward message from terminal observaion\"\"\"\n",
    "        beta = np.zeros((step+1, self.Ns)) # likelihoods\n",
    "        beta[-1] = obs  # observation\n",
    "        for t in range(step, 0, -1): # toward 0\n",
    "            beta[t-1] = beta[t] @ self.ptr\n",
    "        return beta\n",
    "    \n",
    "    def posterior(self, p0, obs, step):\n",
    "        \"\"\"forward-backward algorithm\"\"\"\n",
    "        alpha = self.forward(p0, step)\n",
    "        beta = self.backward(obs, step)\n",
    "        post = alpha*beta\n",
    "        for t in range(step+1):\n",
    "            post[t] = post[t]/sum(post[t])  # normalize        \n",
    "        return post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of directed random walk on a ring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stochastic cycling on a ring\n",
    "ns = 6   # ring size\n",
    "ps = 0.3  # shift probability\n",
    "Ptr = np.zeros((ns, ns))  # transition matrix\n",
    "for i in range(ns):\n",
    "    Ptr[i,i] = 1 - ps\n",
    "    Ptr[(i+1)%ns, i] = ps\n",
    "plt.imshow(Ptr)\n",
    "# create a Markov chain\n",
    "ring = Markov(Ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a sample trajectory\n",
    "T = 15\n",
    "ring.sample(1, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward message passing\n",
    "alpha = ring.forward([0,0,1,0,0,0], T)\n",
    "plt.imshow(alpha.T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward message passing\n",
    "beta = ring.backward([0,0,0,1,0,0], T)\n",
    "plt.imshow(beta.T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior by their products\n",
    "post = ring.posterior([0,0,1,0,0,0], [0,0,0,1,0,0], T)\n",
    "plt.imshow(post.T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a little shifted observation\n",
    "post = ring.posterior([0,0,1,0,0,0], [0,0,0,0,1,0], T)\n",
    "plt.imshow(post.T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# longer sequence\n",
    "post = ring.posterior([0,0,1,0,0,0], [0,0,0,0,1,0], 3*T)\n",
    "plt.imshow(post.T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Bayesian Inference\n",
    "\n",
    "Iterative Bayesian inference can be generalized to the case when the hidden variable $x$ changes dynamically.\n",
    "\n",
    "We denote the sequence of observation as\n",
    "\n",
    "$$  y_{1:t}=(y_1,..,y_t) $$\n",
    "\n",
    "and the history of underlying state variable as\n",
    "\n",
    "$$  x_{1:t}=(x_1,..,x_t). $$\n",
    "\n",
    "We assume two conditional probability distributions:\n",
    "\n",
    "* Dynamics model: $p(x’|x)$\n",
    "\n",
    "* Observation model: $p(y|x)$\n",
    "\n",
    "Using the posterior $p(x_t|y_{1:t})$ computed from the data up to time $t$, we use the dymamics model to compute the *predictive prior*:\n",
    "\n",
    "$$  p(x_{t+1}|y_{1:t}) = \\int p(x_{t+1}|x_t) p(x_t|y_{1:t}) dx_t $$\n",
    "\n",
    "by integrating or summing over the possible range of $x$.\n",
    "\n",
    "We can combine this prior with the new coming data $y_{t+1}$ to update the posterior as:\n",
    "\n",
    "$$  p(x_{t+1}|y_{1:t+1}) \n",
    " = \\frac{p(y_{t+1}|x_{t+1}) p(x_{t+1}|y_{1:t})}{ p(y_{1:t+1})}. $$\n",
    "\n",
    "This is called *dynamic Bayesian inference* and allows real-time tracking of hidden variables from noisy observations.\n",
    "\n",
    "When $x$ is discrete, the process is called *hidden Markov model (HMM)*, which has been used extensively speech processing.\n",
    "\n",
    "Another example is *Kalman filter*, in which $x$ and $y$ are continuous and the dynamics and observation models are linear mapping with Gaussian noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Hidden Markov model\n",
    "\n",
    "Here is a simple implementation of HMM based on the Markov chain above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM(Markov):\n",
    "    \"\"\"Hidden Markov model\"\"\"\n",
    "\n",
    "    def __init__(self, ptr, pobs):\n",
    "        \"\"\"Create HMM with transition and observation models\"\"\"\n",
    "        super().__init__(ptr)\n",
    "        self.pobs = pobs  # observation model\n",
    "        self.No = len(pobs)  # number of observations\n",
    "        self.pst = np.ones(self.Ns)/self.Ns  # state distribution\n",
    "        self.pred = np.zeros(self.Ns)  # predictive distribution\n",
    "\n",
    "    def sample(self, x0=0, step=10):\n",
    "        \"\"\"generate a sample sequence from x0\"\"\"\n",
    "        xt = np.zeros(step, dtype=int) # state sequence\n",
    "        yt = np.zeros(step, dtype=int) # observation sequence\n",
    "        xt[0] = x0\n",
    "        po = self.pobs[:, x0] # prob. of observation\n",
    "        yt[0] = np.random.choice(self.No, p=po) # observe\n",
    "        for t in range(1, step):\n",
    "            ps = self.ptr[:, xt[t-1]]  # prob. of new states\n",
    "            xt[t] = np.random.choice(self.Ns, p=ps) # transit \n",
    "            po = self.pobs[:, xt[t]]   # prob. of observation\n",
    "            yt[t] = np.random.choice(self.No, p=po) # observe \n",
    "        return xt, yt\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"predictive prior by transition model\"\"\"\n",
    "        self.pred = self.ptr @ self.pst\n",
    "    \n",
    "    def update(self, obs):\n",
    "        \"\"\"update posterior by observation\"\"\"\n",
    "        prl = self.pobs[obs]*self.pred # likelihood*prior\n",
    "        self.pst = prl/sum(prl)  #normalize\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"reset state probability\"\"\"\n",
    "        self.pst = np.ones(self.Ns)/self.Ns  # uniform\n",
    "\n",
    "    def step(self, obs):\n",
    "        \"\"\"one step of dynamic bayesian inference\"\"\"\n",
    "        self.predict()\n",
    "        self.update(obs)\n",
    "        return self.pst  # new prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of directed random walk on a ring, like a mouse walking on a circular track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random walk on a ring\n",
    "ns = 6   # ring size\n",
    "ps = 0.3  # shift probability\n",
    "Ptr = np.zeros((ns, ns))  # transition matrix\n",
    "for i in range(ns):\n",
    "    Ptr[i,i] = 1 - ps\n",
    "    Ptr[(i+1)%ns, i] = ps\n",
    "plt.imshow(Ptr)\n",
    "plt.xlabel(\"state\"); plt.ylabel(\"next state\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have three coarse position sensors, which send signal only intermittently, and we want to estimate where the mouse is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blurred intermittent observation model\n",
    "no = 4\n",
    "po = 0.3\n",
    "Pobs = np.zeros((no, ns))  # p(obs|state)\n",
    "Pobs[0,:] = 1 - po  # no information\n",
    "Pobs[1,1] = Pobs[2,3] = Pobs[3,5] = po\n",
    "Pobs[1,0] = Pobs[3,0] = Pobs[1:3,2] = Pobs[2:4,4] = po/2\n",
    "plt.imshow(Pobs)\n",
    "plt.xlabel(\"state\"); plt.ylabel(\"observation\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crate a HMM\n",
    "ring = HMM(Ptr, Pobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample a state trajectory and observations\n",
    "T = 30\n",
    "xt, yt, = ring.sample(1, T)\n",
    "plt.plot(xt)\n",
    "plt.plot(2*yt-1, 'ro');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From such noisy intermittent observations, how can we estimate the state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic Bayesian inference in HMM\n",
    "post = np.zeros((T, ns))  # posterior trajectory\n",
    "ring.reset()\n",
    "for t in range(T):\n",
    "    post[t] = ring.step(yt[t])\n",
    "plt.imshow(post.T, origin='lower')\n",
    "plt.xlabel('t'); plt.ylabel('state');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even when there is no useful sensory input, you can predict the state distribution by the dynamic model.\n",
    "When a sensory input becomes available, prediction is corrected and sharpened.\n",
    "\n",
    "After sensory input, you can also reflect back and consider which previous states were more likely using *forward-backward* algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximate Bayesian inference\n",
    "\n",
    "For discrete distributions and continuous distributions following Gaussians and some others, computation of posterior distribution is not too difficult.\n",
    "\n",
    "For example, if the likelihood function and the prior distribution follow certain distributions like Gaussian, we can just keep track of the parameters of the distribution and the normalizing factor is given analytically. For example, if both the likelihood and the prior and Gaussian, we can match the second and first-order coefficients of the exponent as $-\\frac{1}{2\\sigma^2}$ and $\\frac{\\mu}{\\sigma^2}$ and then the normalizing factor is analytically given as $\\sqrt{2\\pi\\sigma^2}$.\n",
    "\n",
    "But when we deal with an arbitrary high-dimension continous distributions, computation of posterior distribution. Especially the computation of the normalizaing factor (marginal likelihood) can be quite hard for integration over multiple dimensions.\n",
    "\n",
    "For such cases, there are approximate Bayesian inference methods, such as *variational inference* and *sampling methods*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational inference\n",
    "\n",
    "In variational inference, we approximate the posterior distribution by a certain functional form $q(x)$, and update it to minimize the discrepancy from the posterior distribuion, usually measured by the *KL divergence*\n",
    "\n",
    "$$ KL[q(x);p(x|y)] = \\int q(x) \\log\\frac{q(x)}{p(x|y)} dx $$\n",
    "\n",
    "A typical assumption is that the posterior distribution can be factorized, i.e. represented by a product of distributions of different groups\n",
    "\n",
    "$$ q(x) = \\prod_i q_i(x_i). $$\n",
    "\n",
    "This leads to an repeated alternating optimization similar to the EM algorithm, but by taking into account the distribution of each group of variables.\n",
    "\n",
    "See Chapter 10 of Bishop (2006) for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling methods: \n",
    "\n",
    "In the sampling methods, we approximate a distribution $p(x)$ by a collection of points $\\{x_1,...,x_n\\}$.\n",
    "\n",
    "We are often interested in evaluating the expectation of a certain function over the posterior distribution\n",
    "\n",
    "$$ E_{p(x)}[f(x)] = \\int f(x)p(x) dx $$\n",
    "\n",
    "This can be approximated by the sum of the values at the sample points\n",
    "\n",
    "$$ E_{p(x)}[f(x)] = \\frac{1}{n} \\sum_{i=1}^n f(x_i) $$\n",
    "\n",
    "if the distribution of samples ${x_i}$ well approximates $p(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov chain Monte Carlo (MCMC)\n",
    "\n",
    "*Markov chain Monte Carlo (MCMC)* takes a new sample near the previous sample and accept or reject it based on unnormalized correlates of the target probability, such as the product of the likelihood and the prior, so that the sequence of samples follows the target distribution, such as the posterior distribution in Bayesian inference.\n",
    "\n",
    "A simple example of MCMC is *Metropolis sampling*, which requires only unnormalized propability $\\tilde{p}(x)\\propto p(x)$ of samples for relative comparison.\n",
    "\n",
    "A new candidate $x^*$ is generated by a symmetric proposal distribution $q(x^*|x_k)=q(x_k|x^*)$, such as a gaussian distribution, and acctepted with the probability\n",
    "\n",
    "$$ p_\\mbox{acc} = \\min(1, \\frac{\\tilde{p}(x^*)}{\\tilde{p}(x_k)}) $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis(p, x0, sig=0.1, m=1000):\n",
    "    \"\"\"metropolis: Metropolis sampling\n",
    "    p:unnormalized probability, x0:initial point,\n",
    "    sig:sd of proposal distribution, m:number of sampling\"\"\"\n",
    "    n = len(x0)  # dimension\n",
    "    p0 = p(x0)\n",
    "    x = []\n",
    "    for i in range(m):\n",
    "        x1 = x0 + sig*np.random.randn(n)\n",
    "        p1 = p(x1)\n",
    "        pacc = min(1, p1/p0)\n",
    "        if np.random.rand()<pacc:\n",
    "            x.append(x1)\n",
    "            x0 = x1\n",
    "            p0 = p1\n",
    "    return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def croissant(x):\n",
    "    \"\"\"croissant-like unnormalized distribution in 2D\"\"\"\n",
    "    return np.exp(-x[0]**2 - (x[1]-x[0]**2)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 4  # plot rage\n",
    "x = np.linspace(-r, r)\n",
    "X, Y = np.meshgrid(x, x)\n",
    "P = croissant(np.array([X,Y]))\n",
    "plt.contour(X, Y, P)  # target\n",
    "x = metropolis(croissant, [3,0], sig=0.1, m=3000)\n",
    "s = len(x); print(s)  # accepted samples\n",
    "plt.scatter(x[:,0], x[:,1], c=np.arange(s), marker='.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian sensorimotor processing\n",
    "\n",
    "Our life is full of uncertainty. In sensory perception, we need to cope with noise, delay and occulusion and also overcome fundamental ill-posedness, such as to identify the 3D location of your target from 2D retinal images or sounds to two ears.\n",
    "\n",
    "To find a practical solution to such ill-posed problems, we need to make use of some prior assumptions, such as the light usually comes from the top or objects don't jump abruptly.\n",
    "\n",
    "Bayesian inference provides a principled way for combining any prior knowledge with sensory evidence. Indeed there are several lines of psychological evidence suggesting that humans and animals integrate knowledge from prior experience or multi-modal sensory information as predicted by Bayesian inference (Knill & Pouget 2004, Doya et al. 2007).\n",
    "\n",
    "* Ernst & Banks (2002) tested in a grasping task in a virtual reality setting how human subjects' object size perception depends on the noise level in the visula feedback. They showed that as the viaual noise increases, subjects' responses are closer to the size estimated by the haptic input, consistently with the ratio of the variances or visual and haptic perception as predicted by the Bayesian theory of multisensory integration.\n",
    "\n",
    "* Kording & Wolpert (2004) tested in an arm reaching task with modified visual feedback how the prior expectation based on repeated trials is combined with visual feedback of different clarities upon each trial. They showed that the subjects' performance was based more on the visual feedback for higher clarity, as expected from Bayesian integration of the prior and likehihood by their variances.\n",
    "\n",
    ">![Hewitson2018_Fig1](figures/Hewitson2018_Fig1.jpg)\n",
    ">![Hewitson2018_Fig3](figures/Hewitson2018_Fig3.jpg)\n",
    ">\n",
    "> This is a study by Hewitson et al. (2018) following the experiment by Wolpert & Koerding (2004). As the subject tries to move the cursor to the target, a random shift is introduced to the hand-to-curs mapping. The subjects acquire a prior distribution of the cursor shift from experience, and combine that with sensory feedback with different clarities in the middle of reaching. They confirmed that the subjects' performance followed the predicted by Bayesian inference and further showed that the performace generalize across the arm used (from Hewitson et al. 2018)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Bayesian computation in the brain\n",
    "\n",
    "How such Bayesian computation realized in the brain? How does the brain represent and manipulate probability distributions?\n",
    "\n",
    "One possibility is that the *receptive field* of a neuron represents a basis function in the sensory space and the activities of a population of neurons represent a probability distribution. This idea is called *probabilistic population code* (Zemel et al. 2004, Ma et al. 2006).\n",
    "\n",
    "The cerebral cortex has a hierarchical organization and bi-directional connections between lower and higher areas originating from specific layers. \n",
    "There have been serveral hypotheses about how such hierarchical recurrent network can realize Bayesian inference, such as by belif propagation (Lochmann & Deneve 2011; George D, Hawkins J 2009).\n",
    "\n",
    ">![George2009_Fig9](figures/George2009_Fig9.png)\n",
    ">\n",
    "> A hypothetical diagram of how bottom-up (green) and top-down (red) messages for Bayesian inference are processed by neurons in different cortical layers. From George and Hawkins (2009)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Karl Frisont considered variational approximation as a plausible mechanism of Bayesian inference in the brain and proposed the minimization of *variational free energy* as the basic operational principle of the brain (Friston 2005, 2010).\n",
    "His group proposed how such operations can be implemented in the canonical cortical circuits (Bastos et al. 2012).\n",
    "\n",
    ">![Bastos2012](https://ars.els-cdn.com/content/image/1-s2.0-S0896627312009592-gr5_lrg.jpg)\n",
    ">\n",
    ">Bastos and colleagues proposed a hypothesis about how Bayesian inference by variational approximation, know as *predictive coding* can be implemented in the canonical cortical circuits (from Bastos et al., 2012)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Experimental investigation of Bayesian inference in the brin\n",
    "\n",
    "To test the hypotheses that cortical circuits perform dynamics Bayesian inference, Funamize et al. (2016) trained mice to navigate in an auditory virtual environment with head fixed and performed calcium imaging of neurons in the parietal cortes by a two-photon microscope. Bayesian decoding of neural population activity by the method of Ma et al. (2006) showed that the inferred goal distance reduced even while auditory feedback was turned off, presumably by using action-dependent state transition model, and the variace of the goal distance was reduced as the auditory feedback was turned on again, similar to the feature of dynamic Bayesian inference.\n",
    "\n",
    "> ![Funamizu2016](figures/Funamizu2016_Fig4a.png)\n",
    ">Left: goal distance tuning of recorded neurons. Right: from the instantaneous observation of the population neural activity, by combination of the likelihoods and a flat prior, the posterior distribution of the goal distance was computed by probabilistic population coding model (Ma et al, 2006). The posterior distribution shifted even when the sound feedback was turoen off (between red bars), and the distribution became sharper when the sound feedback was turned on (red bar). From Funamizu et al. (2016)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* Bishop CM (2006) Pattern Recognition and Machine Learning. Springer. https://www.microsoft.com/en-us/research/people/cmbishop/prml-book/\n",
    "    * Chapter 3: Bayesian linear regression  \n",
    "    * Chapter 8: Graphical models  \n",
    "    * Chapter 10: Approximate Bayesian inference  \n",
    "    * Chapter 11: Sampling methods  \n",
    "    \n",
    "### Bayesian sensorimotor integration\n",
    "\n",
    "* Knill DC, Pouget A (2004) The Bayesian brain: the role of uncertainty in neural coding and computation. Trends in neurosciences 27:712-719. https://doi.org/10.1016/j.tins.2004.10.007  \n",
    "* Doya K, Ishii S, Pouget A, Rao R (2007) Bayesian Brain: Probabilistic Approach to Neural Coding and Learning. MIT Press.  \n",
    "* Ernst MO, Banks MS (2002). Humans integrate visual and haptic information in a statistically optimal fashion. Nature, 415, 429-433. https://doi.org/10.1038/415429a  \n",
    "* Körding KP, Wolpert DM (2004) Bayesian integration in sensorimotor learning. Nature 427:244-247. https://doi.org/10.1038/nature02169  \n",
    "* Hewitson CL, Sowman PF, Kaplan DM (2018). Interlimb Generalization of Learned Bayesian Visuomotor Prior Occurs in Extrinsic Coordinates. eneuro, 10.1523/eneuro.0183-18.2018. https://doi.org/10.1523/eneuro.0183-18.2018  \n",
    "\n",
    "### Probabilistic population codes\n",
    "\n",
    "* Zemel RS, Dayan P, Pouget A (1998) Probabilistic interpretation of population codes. Neural computation 10:403-430. https://doi.org/10.1162/089976698300017818\n",
    "* Ma WJ, Beck JM, Latham PE, Pouget A (2006) Bayesian inference with probabilistic population codes. Nature neuroscience 9:1432-1438. https://doi.org/10.1038/nn1790\n",
    "\n",
    "### Baysian inference in the cortical circuit\n",
    "\n",
    "* George D, Hawkins J (2009). Towards a mathematical theory of cortical micro-circuits. PLoS Comput Biol, 5, e1000532. https://doi.org/10.1371/journal.pcbi.1000532  \n",
    "* Lochmann T, Deneve S (2011) Neural processing as causal inference. Current opinion in neurobiology 21:774-781. https://doi.org/10.1016/j.conb.2011.05.018  \n",
    "* Friston K (2005). A theory of cortical responses. Philos Trans R Soc Lond B Biol Sci, 360, 815-36. http://doi.org/10.1098/rstb.2005.1622  \n",
    "* Friston K (2010). The free-energy principle: a unified brain theory? Nat Rev Neurosci, 11, 127-38. http://doi.org/10.1038/nrn2787  \n",
    "* Bastos AM, Usrey WM, Adams RA, Mangun GR, Fries P, Friston KJ (2012). Canonical microcircuits for predictive coding. Neuron, 76, 695-711. https://doi.org/10.1016/j.neuron.2012.10.038  \n",
    "* Bogacz R (2017) A tutorial on the free-energy framework for modelling perception and learning. Journal of Mathematical Psychology. 76, 198–211. https://doi.org/10.1016/j.jmp.2015.11.003  \n",
    "* Funamizu A, Kuhn B, Doya K (2016) Neural substrate of dynamic Bayesian inference in the cerebral cortex. Nature Neuroscience 19:1682-1689. https://doi.org/10.1038/nn.4390"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
